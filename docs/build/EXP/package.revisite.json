[
  {
    "name": "expression.besoin.revise.md",
    "content": "# Créateur d'ontologie\r\n\r\n## Version\r\n\r\nVersion 0.4.0 Révision basée sur l'implémentation et les retours d'exécution détaillés\r\n\r\n## Aperçu du projet\r\n\r\nDévelopper un logiciel en Go qui, à partir de divers formats de documents (texte, PDF, Markdown, HTML, DOCX), crée une ontologie au format QuickStatement pour être compatible avec Wikibase. Le logiciel doit identifier et extraire chaque élément d'information du document d'entrée, tout en gérant efficacement les très grands documents, les variations linguistiques et les termes composés.\r\n\r\n## Fonctionnalités principales\r\n\r\n### 1. Support Multi-format d'Entrée\r\n- Accepter les entrées en formats texte, PDF, Markdown, HTML et DOCX\r\n- Implémenter des analyseurs robustes pour chaque format supporté\r\n- Prise en charge de très grands documents (dépassant 120 000 tokens)\r\n- Extraction cohérente des métadonnées à travers les différents formats\r\n\r\n### 2. Traitement linguistique et normalisation\r\n- Implémenter une fonction de normalisation robuste pour les mots et termes\r\n  - Conversion en minuscules\r\n  - Remplacement des underscores par des espaces\r\n  - Suppression de la ponctuation et des caractères non alphanumériques\r\n  - Gestion appropriée des espaces\r\n- Développer des méthodes pour gérer les variations linguistiques\r\n- Évaluer et potentiellement intégrer des bibliothèques de traitement du langage naturel\r\n\r\n### 3. Indexation et recherche de positions\r\n- Créer un système d'indexation sophistiqué\r\n  - Indexer les mots individuels et leurs combinaisons (jusqu'à 3 mots)\r\n  - Gérer efficacement les termes composés\r\n- Implémenter une fonction de recherche de positions avancée\r\n  - Supporter la recherche exacte et partielle\r\n  - Gérer efficacement les termes composés et leurs variations\r\n- Optimiser les performances d'indexation et de recherche pour les grands documents\r\n\r\n### 4. Génération et Enrichissement d'une ontologie\r\n- Générer une sortie QuickStatement détaillée utilisant le vocabulaire Wikibase\r\n- Implémenter un processus d'enrichissement d'ontologie multi-passes\r\n- Développer une logique de fusion intelligente pour intégrer les nouveaux résultats de manière cohérente\r\n- Gérer efficacement les positions multiples pour chaque concept\r\n- Assurer une extraction complète des informations des documents d'entrée\r\n- Traiter plusieurs documents en utilisant la même ontologie\r\n- Ajouter des options d'export en formats RDF et OWL\r\n\r\n### 5. Intégration LLM\r\n- Supporter plusieurs LLMs, au minimum OpenAI GPT-4, Claude 3.5 Sonnet, Ollama\r\n- Implémenter une gestion robuste des limites de taux des API LLM\r\n- Optimiser les appels API aux LLMs pour réduire les coûts et les temps de traitement\r\n- Développer des prompts spécifiques pour l'extraction d'entités, de relations et leurs descriptions\r\n\r\n### 6. Système de Journalisation et Débogage\r\n- Implémenter un système de journalisation polyvalent avec support pour les niveaux debug, info, warning et error\r\n- Ajouter un mode de débogage détaillé activable via une option --debug\r\n- Implémenter des logs détaillés à chaque étape du processus pour faciliter le débogage\r\n- Assurer que l'activation du mode debug n'affecte pas significativement les performances en mode normal\r\n\r\n### 7. Architecture et Modularité\r\n- Utiliser Cobra pour la gestion des commandes CLI\r\n- Implémenter une architecture pipeline pour un traitement efficace des documents\r\n- Créer une couche d'abstraction pour les LLMs pour faciliter l'ajout futur de nouveaux modèles\r\n- Concevoir une architecture flexible pour éviter les cycles d'importation entre packages\r\n\r\n### 8. Gestion des Erreurs et Robustesse\r\n- Implémenter une gestion fine des erreurs pour les appels API aux LLMs\r\n- Assurer une validation rigoureuse des entrées et des sorties à chaque étape du pipeline\r\n- Gérer de manière appropriée les erreurs spécifiques aux API LLM et aux opérations de fichiers\r\n\r\n### 9. Optimisation des Performances\r\n- Optimiser le traitement par lots des grands documents\r\n- Implémenter des stratégies d'optimisation de la mémoire\r\n- Utiliser des techniques de streaming et buffering pour les grands fichiers\r\n- Optimiser l'indexation et la recherche pour les documents volumineux et les termes composés\r\n\r\n### 10. Tests et Validation\r\n- Implémenter des tests unitaires pour chaque composant\r\n- Créer des tests de bout en bout pour le pipeline complet\r\n- Ajouter des tests spécifiques pour la validation de l'ontologie enrichie\r\n- Implémenter des tests de performance pour le traitement parallèle et multi-passes\r\n- Créer des cas de test pour les scénarios linguistiques complexes (termes composés, variations)\r\n\r\n## Exigences Détaillées\r\n\r\nPour tous les modules :\r\n- Limiter la taille d'un package à maximum 10 méthodes et découper le code logiciel finement\r\n- Optimiser le code pour la performance, particulièrement pour le traitement de grands documents\r\n- Assurer une gestion robuste des erreurs à travers l'application\r\n- Implémenter des logs détaillés pour chaque étape du processus\r\n\r\n### 1. Analyse et Segmentation des Documents\r\n- Développer des modules séparés pour l'analyse de chaque format supporté\r\n- Implémenter un mécanisme de segmentation sophistiqué pour décomposer les grands documents\r\n- Assurer une gestion robuste des erreurs pour les documents mal formés ou incomplets\r\n- Préserver la structure du document et le contexte à travers les segments\r\n\r\n### 2. Traitement Linguistique\r\n- Implémenter une fonction de normalisation robuste pour les mots et termes\r\n- Développer des méthodes pour gérer efficacement les variations linguistiques et les termes composés\r\n- Optimiser les performances de traitement pour les grands volumes de texte\r\n\r\n### 3. Indexation et Recherche\r\n- Créer un système d'indexation efficace pour les mots individuels et les termes composés\r\n- Implémenter une fonction de recherche flexible supportant la recherche exacte et partielle\r\n- Optimiser les performances d'indexation et de recherche pour les grands documents\r\n\r\n### 4. Enrichissement de l'Ontologie\r\n- Développer un processus d'enrichissement itératif de l'ontologie\r\n- Implémenter une gestion efficace des positions multiples pour chaque concept\r\n- Assurer une fusion cohérente des résultats entre les passes d'enrichissement\r\n\r\n### 5. Intégration LLM et Gestion des Prompts\r\n- Créer une interface commune pour les clients LLM\r\n- Développer des prompts spécifiques pour l'extraction d'entités, de relations et leurs descriptions\r\n- Implémenter une gestion robuste des limites de taux d'API et des erreurs\r\n\r\n### 6. Pipeline de Traitement Principal\r\n- Intégrer tous les composants dans un pipeline de traitement cohérent\r\n- Implémenter un traitement parallèle et multi-passes efficace\r\n- Assurer une gestion robuste des erreurs et des cas limites\r\n\r\n## Contraintes Techniques\r\n- Développer en langage de programmation Go\r\n- Suivre les meilleures pratiques et les modèles idiomatiques de Go\r\n- Utiliser les goroutines et les canaux pour le traitement concurrent lorsque c'est approprié\r\n- Assurer la compatibilité avec différents LLM et leurs limites de contexte spécifiques\r\n- Une méthode ne peut pas faire plus de 80 lignes\r\n- Un fichier de code source Go d'un package pas plus de 10 méthodes\r\n\r\n## Livrables\r\n1. Dépôt de code source avec des packages Go bien structurés\r\n2. Binaires exécutables pour les principaux systèmes d'exploitation (Windows, macOS, Linux)\r\n3. Suite de tests complète incluant des tests de performance et de stress\r\n4. Documentation utilisateur et technique détaillée\r\n5. Fichiers de configuration d'exemple\r\n6. README avec un guide de démarrage rapide et des instructions d'utilisation de base\r\n7. Licence GPL3",
    "size": 7807,
    "modTime": "2024-10-22T23:26:28.1659984+02:00",
    "path": "expression.besoin.revise.md"
  },
  {
    "name": "planaction.revisite.md",
    "content": "# Plan d'action révisé pour le projet Ontology\r\n\r\n1. Configuration et structure de base\r\n   - Créer la structure du projet\r\n   - Implémenter le système de configuration YAML\r\n   - Mettre en place Cobra pour la gestion des commandes CLI\r\n   - Créer le package d'internationalisation (i18n)\r\n\r\n2. Système de journalisation\r\n   - Développer le module de journalisation avec différents niveaux de log\r\n   - Implémenter le mode de débogage détaillé (--debug)\r\n   - Ajouter le mode silencieux (--silent)\r\n   - Mettre en place la rotation et l'archivage des logs\r\n   - Intégrer des métriques de performance dans les logs\r\n\r\n3. Architecture et structure de données\r\n   - Créer un package `model` pour les structures de données de base\r\n   - Définir la structure `OntologyElement` avec un champ pour les descriptions et les positions multiples\r\n   - Implémenter une structure `Relation` pour représenter les relations entre entités\r\n   - Concevoir une architecture flexible pour éviter les cycles d'importation entre packages\r\n\r\n4. Traitement linguistique et normalisation\r\n   - Implémenter une fonction `normalizeWord` robuste\r\n     - Conversion en minuscules\r\n     - Remplacement des underscores par des espaces\r\n     - Suppression de la ponctuation et des caractères non alphanumériques\r\n     - Gestion des espaces en début et fin de chaîne\r\n   - Développer des méthodes pour gérer les variations linguistiques\r\n   - Évaluer l'utilisation de bibliothèques de traitement du langage naturel\r\n\r\n5. Indexation et recherche de positions\r\n   - Améliorer la fonction `createPositionIndex`\r\n     - Indexer les mots individuels et leurs combinaisons (jusqu'à 3 mots)\r\n     - Gérer toutes les combinaisons possibles de mots composés\r\n   - Créer une fonction `findPositions` sophistiquée\r\n     - Implémenter une recherche exacte et partielle\r\n     - Gérer efficacement les termes composés\r\n   - Optimiser les performances d'indexation et de recherche\r\n\r\n6. Enrichissement de l'ontologie\r\n   - Mettre à jour `enrichOntologyWithPositions`\r\n     - Utiliser `findPositions` pour localiser les concepts\r\n     - Améliorer la gestion des entités et des relations\r\n   - Implémenter une gestion robuste des positions multiples\r\n\r\n7. Système de prompts et intégration LLM\r\n   - Créer des templates de prompts flexibles\r\n   - Implémenter les clients pour différents LLMs (OpenAI, Claude, Ollama)\r\n   - Développer un système de gestion des limites de taux d'API\r\n   - Optimiser les appels API pour réduire les coûts et les temps de traitement\r\n\r\n8. Pipeline de traitement principal\r\n   - Intégrer tous les composants dans un pipeline cohérent\r\n   - Implémenter le traitement par lots pour les grands documents\r\n   - Développer un système de traitement multi-passes\r\n   - Mettre en place un traitement parallèle des segments\r\n\r\n9. Optimisation des performances\r\n   - Optimiser l'indexation et la recherche pour les grands documents\r\n   - Implémenter des stratégies d'optimisation de la mémoire\r\n   - Utiliser des techniques de streaming et buffering pour les grands fichiers\r\n\r\n10. Logging et débogage avancés\r\n    - Implémenter un système de logging détaillé à chaque étape du processus\r\n    - Ajouter des logs pour afficher l'état de l'ontologie et de l'index à différentes étapes\r\n    - Développer des outils de débogage pour les scénarios complexes\r\n\r\n11. Fonctionnalités d'export\r\n    - Implémenter l'export en format RDF et OWL\r\n    - Créer un format de sortie clair séparant les entités et les relations\r\n\r\n12. Tests et validation\r\n    - Créer des tests unitaires pour chaque composant\r\n    - Développer des tests d'intégration pour le pipeline complet\r\n    - Implémenter des tests spécifiques pour la gestion des positions multiples et des termes composés\r\n    - Créer des cas de test pour les scénarios linguistiques complexes\r\n\r\n13. Documentation et finalisation\r\n    - Rédiger une documentation technique détaillée\r\n    - Créer des guides utilisateur et développeur\r\n    - Préparer des sessions de formation sur les aspects complexes du système\r\n\r\n14. Révision et optimisation finale\r\n    - Effectuer une revue complète du code\r\n    - Optimiser les performances globales du système\r\n    - Réaliser des tests de charge et de stress",
    "size": 4314,
    "modTime": "2024-10-22T23:25:04.5301022+02:00",
    "path": "planaction.revisite.md"
  }
]