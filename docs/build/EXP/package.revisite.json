[
  {
    "name": "expression.besoin.revise.md",
    "content": "# Créateur d'ontologie\r\n\r\n## Version\r\n\r\nVersion 0.4.0 Révision basée sur l'implémentation et les retours d'expérience\r\n\r\n## Aperçu du projet\r\n\r\nDévelopper un logiciel en Go qui, à partir de divers formats de documents (texte, PDF, Markdown, HTML, DOCX), crée une ontologie au format QuickStatement compatible avec Wikibase. Le logiciel doit identifier et extraire chaque élément d'information du document d'entrée, tout en gérant efficacement les très grands documents et en permettant un enrichissement itératif de l'ontologie, avec une flexibilité accrue dans la configuration et le traitement des données.\r\n\r\n## Fonctionnalités principales\r\n\r\n### 1. Support Multi-format d'Entrée\r\n- Accepter les entrées en formats texte, PDF, Markdown, HTML et DOCX\r\n- Implémenter des analyseurs robustes pour chaque format supporté\r\n- Pour les PDFs, utiliser la bibliothèque github.com/ledongthuc/pdf pour l'extraction de texte et de métadonnées\r\n- Prise en charge de très grands documents (dépassant 120 000 tokens)\r\n- Extraction cohérente des métadonnées à travers les différents formats\r\n\r\n### 2. Génération et Enrichissement d'une ontologie au format QuickStatement / Wikibase\r\n- Générer une sortie QuickStatement détaillée utilisant le vocabulaire Wikibase\r\n- Implémenter un processus d'enrichissement d'ontologie multi-passes\r\n- Utiliser des prompts spécifiques pour l'enrichissement initial et la fusion des résultats\r\n- Développer une logique de fusion intelligente pour intégrer les nouveaux résultats de manière cohérente\r\n- Gérer le contexte entre les segments et les passes d'enrichissement\r\n- Implémenter un traitement complexe des chaînes de caractères pour gérer correctement les caractères d'échappement\r\n- Assurer une extraction complète des informations des documents d'entrée\r\n- Découper les documents larges en segments basés sur le nombre de tokens\r\n- S'assurer que chaque élément de l'ontologie est unitaire entre les segments et que le tout est cohérent\r\n- Traiter plusieurs documents en utilisant la même ontologie\r\n- Le résultat de l'exécution du logiciel est un fichier ayant l'extension .tsv (tab separated value)\r\n- Ajouter des options d'export en formats RDF et OWL\r\n\r\n### 3. Segmentation et traitement du contenu\r\n- Implémenter une segmentation sophistiquée créant des segments cohérents basés sur le nombre de tokens\r\n- Utiliser tiktoken-go pour le comptage précis des tokens\r\n- Optimiser la fonction de segmentation pour gérer efficacement de grands volumes de texte\r\n- Implémenter une gestion efficace de la mémoire pour les très grands documents\r\n- Assurer une intégration fluide entre le segmenter et le client LLM, en ajustant la taille des segments et la gestion du contexte\r\n\r\n### 4. Intégration LLM\r\n- Supporter plusieurs LLMs, au minimum OpenAI GPT-4, Claude 3.5 Sonnet, Ollama\r\n- Implémenter une gestion robuste des limites de taux des API LLM, incluant un système de \"token bucket\" dans le client Claude (claude.go)\r\n- Implémenter un backoff exponentiel avec un maximum de 5 tentatives pour les erreurs de limite de taux\r\n- Gérer les différences entre les APIs d'OpenAI, Claude, et Ollama avec des adaptateurs spécifiques\r\n- Optimiser les appels API aux LLMs pour réduire les coûts et les temps de traitement\r\n\r\n### 5. Système de Prompts\r\n- Implémenter un système de templates de prompts sophistiqué et flexible\r\n- Créer une structure PromptTemplate avec des méthodes pour formater les prompts\r\n- Créer des prompts spécifiques pour l'extraction d'entités, de relations, l'enrichissement d'ontologie et la fusion des résultats\r\n- Assurer la compatibilité des prompts avec différents LLMs\r\n\r\n### 6. Système de Journalisation\r\n- Implémenter un système de journalisation polyvalent avec support pour les niveaux debug, info, warning et error\r\n- Ajouter un mode de débogage détaillé activable via une option --debug\r\n- Assurer que l'activation du mode debug n'affecte pas significativement les performances en mode normal\r\n- Exporter les logs vers des fichiers texte et les afficher sur la console\r\n- Implémenter un mode silencieux (--silent) pour désactiver la sortie console des logs\r\n- Inclure des métriques de performance dans les logs, notamment pour le traitement parallèle et multi-passes\r\n\r\n### 7. Gestion de la Configuration\r\n- Utiliser YAML pour une configuration centralisée\r\n- Permettre des surcharges de paramètres par ligne de commande\r\n- Inclure des options de configuration pour les différents LLMs et leurs modèles spécifiques\r\n- Implémenter des options de configuration flexibles, y compris le contrôle de l'inclusion des positions dans l'ontologie\r\n\r\n### 8. Architecture et Modularité\r\n- Utiliser Cobra pour la gestion des commandes CLI\r\n- Implémenter une architecture pipeline pour un traitement efficace des documents\r\n- Créer une couche d'abstraction pour les LLMs pour faciliter l'ajout futur de nouveaux modèles\r\n- Séparer le système de prompts en son propre module pour améliorer la modularité et la réutilisabilité\r\n- Implémenter un traitement parallèle des segments avec des goroutines pour améliorer les performances\r\n- Concevoir une architecture flexible pour faciliter l'ajout de nouvelles options de configuration\r\n\r\n### 9. Gestion des Erreurs et Robustesse\r\n- Implémenter une gestion fine des erreurs pour les appels API aux LLMs, y compris la gestion des timeouts et des retries\r\n- Assurer une validation rigoureuse des entrées et des sorties à chaque étape du pipeline\r\n- Gérer de manière appropriée les erreurs spécifiques aux API LLM\r\n- Implémenter une gestion robuste des erreurs lors de la fusion des résultats entre les passes\r\n\r\n### 10. Tests et Validation\r\n- Implémenter des tests unitaires pour chaque composant\r\n- Créer des tests de bout en bout pour le pipeline complet\r\n- Ajouter des tests de performance et de charge pour valider le comportement avec de grands volumes de données\r\n- Inclure des tests spécifiques pour le mode de débogage et les nouvelles fonctionnalités de journalisation\r\n- Implémenter des tests de charge spécifiques pour vérifier le comportement du système sous des conditions de limite de taux\r\n- Ajouter des tests spécifiques pour la validation de l'ontologie enrichie après fusion\r\n- Implémenter des tests de performance pour le traitement parallèle et multi-passes\r\n- Ajouter des tests spécifiques pour vérifier le comportement avec et sans l'inclusion des positions\r\n\r\n### 11. Optimisation de la mémoire et des performances\r\n- Implémenter des stratégies d'optimisation de la mémoire pour le traitement de très grands documents\r\n- Utiliser des techniques de streaming et de buffering pour minimiser l'utilisation de la mémoire lors du traitement de grands fichiers\r\n- Optimiser le traitement par lots des grands documents pour éviter les problèmes de mémoire\r\n- Implémenter des stratégies d'optimisation pour les appels API aux LLMs afin de réduire les coûts et les temps de traitement\r\n\r\n### 12. Gestion des positions et relations\r\n- Implémenter un système de gestion des positions multiples pour chaque entité de l'ontologie\r\n- Supporter les entités composées de plusieurs mots (jusqu'à 3 mots)\r\n- Créer une structure distincte pour représenter les relations entre les entités\r\n- Développer un format de sortie flexible qui peut inclure ou exclure les informations de position selon la configuration\r\n- Implémenter une recherche flexible des positions, y compris une recherche partielle pour les mots individuels des noms d'entités\r\n\r\n### 13. Options de configuration flexibles\r\n- Implémenter un système permettant aux utilisateurs de contrôler l'inclusion ou l'exclusion des informations de position dans l'ontologie générée\r\n- Permettre la configuration de cette option via la ligne de commande et le fichier de configuration YAML\r\n- Assurer que toutes les parties du système (pipeline, convertisseur, etc.) respectent cette option de configuration\r\n- Maintenir la cohérence du traitement des données à travers l'application, que les positions soient incluses ou non\r\n\r\n### 14. Sécurité et Confidentialité\r\n- Ajouter une option pour le chiffrement des données sensibles dans les logs et les fichiers de sortie\r\n- Implémenter un système basique de gestion des droits d'accès pour les différentes fonctionnalités\r\n\r\n## Contraintes Techniques\r\n- Développer en langage de programmation Go\r\n- Suivre les meilleures pratiques et les modèles idiomatiques de Go\r\n- Utiliser les goroutines et les canaux pour le traitement concurrent lorsque c'est approprié\r\n- Assurer la compatibilité avec différents LLM et leurs limites de contexte spécifiques\r\n- Une méthode ne peut pas faire plus de 80 lignes\r\n- Un fichier de code source Go d'un package pas plus de 10 méthodes\r\n\r\n## Livrables\r\n1. Dépôt de code source avec des packages Go bien structurés\r\n2. Binaires exécutables pour les principaux systèmes d'exploitation (Windows, macOS, Linux)\r\n3. Suite de tests complète incluant des tests de performance et de stress\r\n4. Documentation utilisateur et technique avec des directives d'optimisation des performances\r\n5. Fichiers de configuration d'exemple\r\n6. README avec un guide de démarrage rapide et des instructions d'utilisation de base\r\n7. Licence GPL3",
    "size": 9351,
    "modTime": "2024-10-24T00:03:12.4562609+02:00",
    "path": "expression.besoin.revise.md"
  },
  {
    "name": "planaction.revisite.md",
    "content": "# Plan d'action révisé pour le projet Ontology\r\n\r\n1. Configuration et structure de base\r\n   - Créer la structure du projet\r\n   - Implémenter le système de configuration YAML\r\n   - Mettre en place Cobra pour la gestion des commandes CLI\r\n   - Créer le package d'internationalisation (i18n)\r\n   - Implémenter des options de configuration flexibles, y compris le contrôle de l'inclusion des positions\r\n\r\n2. Système de journalisation\r\n   - Développer le module de journalisation avec différents niveaux de log\r\n   - Implémenter le mode de débogage détaillé (--debug)\r\n   - Ajouter le mode silencieux (--silent)\r\n   - Mettre en place la rotation et l'archivage des logs\r\n   - Intégrer des métriques de performance dans les logs\r\n\r\n3. Architecture et structure de données\r\n   - Créer un package `model` pour les structures de données de base\r\n   - Définir la structure `OntologyElement` avec un champ pour les descriptions et les positions optionnelles\r\n   - Implémenter une structure `Relation` pour représenter les relations entre entités\r\n   - Concevoir une architecture flexible pour faciliter l'ajout de nouvelles options de configuration\r\n\r\n4. Gestion des erreurs et robustesse\r\n   - Créer un système centralisé de gestion des erreurs\r\n   - Implémenter la logique de retry avec backoff exponentiel\r\n   - Développer des mécanismes de validation pour les entrées et sorties\r\n   - Implémenter une gestion d'erreurs spécifique pour les API LLM et les opérations de fichiers\r\n\r\n5. Système de prompts\r\n   - Créer la structure PromptTemplate\r\n   - Implémenter les méthodes de formatage des prompts\r\n   - Développer des templates pour l'extraction d'entités, de relations et leurs descriptions\r\n   - Créer des prompts spécifiques pour l'enrichissement d'ontologie et la fusion des résultats\r\n\r\n6. Analyse et segmentation des documents\r\n   - Implémenter le parsing pour chaque format de document supporté\r\n   - Développer le mécanisme de segmentation avec tiktoken-go pour le comptage précis des tokens\r\n   - Améliorer la fonction `createPositionIndex` pour capturer les entités composées de plusieurs mots (jusqu'à 3 mots)\r\n   - Implémenter une logique de recherche flexible pour les positions des entités, y compris la recherche partielle\r\n   - Assurer que le système de positionnement fonctionne correctement que les positions soient incluses ou non dans le résultat final\r\n   - Créer le système de gestion des métadonnées\r\n   - Optimiser la gestion de la mémoire pour les grands documents\r\n\r\n7. Intégration LLM\r\n   - Créer une interface commune pour les clients LLM\r\n   - Implémenter les clients pour OpenAI, Claude, et Ollama\r\n   - Développer le système de \"token bucket\" pour la gestion des limites de taux\r\n   - Mettre en place les adaptateurs spécifiques pour chaque API LLM\r\n   - Optimiser les appels API aux LLMs pour réduire les coûts et les temps de traitement\r\n\r\n8. Gestion du contexte et enrichissement d'ontologie\r\n   - Implémenter la gestion du contexte entre les segments\r\n   - Développer le système d'optimisation du contexte pour les LLMs\r\n   - Modifier la fonction `enrichOntologyWithPositions` pour gérer à la fois l'inclusion et l'exclusion des positions\r\n   - Implémenter la gestion des positions multiples pour chaque entité (si l'option est activée)\r\n   - Créer la logique d'enrichissement itératif de l'ontologie\r\n\r\n9. Pipeline de traitement principal\r\n   - Intégrer tous les composants développés dans un pipeline cohérent\r\n   - Implémenter le traitement par lots pour les grands documents\r\n   - Développer le système de traitement multi-passes\r\n   - Adapter le pipeline pour respecter l'option d'inclusion/exclusion des positions\r\n   - Mettre en place le traitement parallèle des segments\r\n   - Implémenter la logique de fusion des résultats après chaque passe\r\n\r\n10. Optimisation des performances\r\n    - Optimiser les appels API aux LLMs\r\n    - Implémenter des stratégies d'optimisation de la mémoire\r\n    - Utiliser des techniques de streaming et buffering pour les grands fichiers\r\n    - Optimiser le traitement parallèle et multi-passes\r\n    - Optimiser la fonction `createPositionIndex` pour les documents volumineux\r\n\r\n11. Logging et débogage\r\n    - Implémenter un système de logging détaillé à travers tout le processus\r\n    - Ajouter des logs de débogage pour afficher l'état de l'ontologie à différentes étapes du traitement\r\n    - Implémenter des métriques de performance pour le suivi du traitement\r\n\r\n12. Fonctionnalités d'export\r\n    - Implémenter l'export en format RDF\r\n    - Développer l'export en format OWL\r\n    - Créer un format de sortie flexible qui peut inclure ou exclure les informations de position selon la configuration\r\n\r\n13. Interface CLI complète\r\n    - Finaliser l'interface de ligne de commande\r\n    - Implémenter le mode interactif\r\n    - Ajouter toutes les options de configuration via les flags, y compris l'option pour inclure/exclure les positions\r\n\r\n14. Tests et validation\r\n    - Créer des tests unitaires pour chaque composant\r\n    - Développer des tests d'intégration pour le pipeline complet\r\n    - Implémenter des tests de performance et de charge\r\n    - Créer des tests spécifiques pour le mode debug et les limites de taux\r\n    - Ajouter des tests pour la validation de l'ontologie enrichie après fusion\r\n    - Implémenter des tests de performance pour le traitement parallèle et multi-passes\r\n    - Ajouter des tests spécifiques pour vérifier le comportement avec et sans l'inclusion des positions\r\n\r\n15. Sécurité et confidentialité\r\n    - Implémenter le chiffrement des données sensibles\r\n    - Développer le système basique de gestion des droits d'accès\r\n\r\n16. Documentation et finalisation\r\n    - Rédiger la documentation utilisateur et technique\r\n    - Créer le README avec guide de démarrage rapide\r\n    - Préparer les fichiers de configuration d'exemple\r\n    - Documenter en détail le processus d'enrichissement itératif de l'ontologie\r\n    - Inclure une documentation spécifique sur l'option d'inclusion/exclusion des positions\r\n    - Générer les binaires pour différents systèmes d'exploitation\r\n    - Préparer des guides ou des sessions de formation pour les développeurs sur la gestion du contexte, la fusion des résultats, et les nouvelles structures de données",
    "size": 6384,
    "modTime": "2024-10-24T00:05:07.8716009+02:00",
    "path": "planaction.revisite.md"
  }
]