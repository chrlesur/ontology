[
  {
    "name": "enrich.go",
    "content": "package ontology\r\n\r\nimport (\r\n    \"fmt\"\r\n\r\n    \"github.com/spf13/cobra\"\r\n    \"github.com/chrlesur/Ontology/internal/logger\"\r\n    \"github.com/chrlesur/Ontology/internal/i18n\"\r\n    \"github.com/chrlesur/Ontology/internal/pipeline\"\r\n)\r\n\r\nvar (\r\n    input     string\r\n    output    string\r\n    format    string\r\n    llm       string\r\n    llmModel  string\r\n    passes    int\r\n    rdf       bool\r\n    owl       bool\r\n    recursive bool\r\n)\r\n\r\n// enrichCmd represents the enrich command\r\nvar enrichCmd = \u0026cobra.Command{\r\n    Use:   \"enrich\",\r\n    Short: i18n.EnrichCmdShortDesc,\r\n    Long:  i18n.EnrichCmdLongDesc,\r\n    Run: func(cmd *cobra.Command, args []string) {\r\n        logger.Info(i18n.StartingEnrichProcess)\r\n        \r\n        // TODO: Implement actual pipeline execution\r\n        err := pipeline.ExecutePipeline()\r\n        if err != nil {\r\n            logger.Error(i18n.ErrorExecutingPipeline, err)\r\n            return\r\n        }\r\n        \r\n        logger.Info(i18n.EnrichProcessCompleted)\r\n    },\r\n}\r\n\r\nfunc init() {\r\n    rootCmd.AddCommand(enrichCmd)\r\n\r\n    enrichCmd.Flags().StringVar(\u0026input, \"input\", \"\", i18n.InputFlagUsage)\r\n    enrichCmd.Flags().StringVar(\u0026output, \"output\", \"\", i18n.OutputFlagUsage)\r\n    enrichCmd.Flags().StringVar(\u0026format, \"format\", \"\", i18n.FormatFlagUsage)\r\n    enrichCmd.Flags().StringVar(\u0026llm, \"llm\", \"\", i18n.LLMFlagUsage)\r\n    enrichCmd.Flags().StringVar(\u0026llmModel, \"llm-model\", \"\", i18n.LLMModelFlagUsage)\r\n    enrichCmd.Flags().IntVar(\u0026passes, \"passes\", 1, i18n.PassesFlagUsage)\r\n    enrichCmd.Flags().BoolVar(\u0026rdf, \"rdf\", false, i18n.RDFFlagUsage)\r\n    enrichCmd.Flags().BoolVar(\u0026owl, \"owl\", false, i18n.OWLFlagUsage)\r\n    enrichCmd.Flags().BoolVar(\u0026recursive, \"recursive\", false, i18n.RecursiveFlagUsage)\r\n\r\n    enrichCmd.MarkFlagRequired(\"input\")\r\n    enrichCmd.MarkFlagRequired(\"output\")\r\n}",
    "size": 1829,
    "modTime": "2024-10-20T12:24:52.447005+02:00",
    "path": "cmd\\ontology\\enrich.go"
  },
  {
    "name": "main.go",
    "content": "// cmd/ontology/main.go\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/chrlesur/Ontology/cmd/ontology\"\n\t\"github.com/chrlesur/Ontology/internal/config\"\n)\n\nfunc main() {\n\tcfg := config.GetConfig()\n\tif err := cfg.ValidateConfig(); err != nil {\n\t\tfmt.Printf(\"Configuration error: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tontology.Execute()\n}\n",
    "size": 330,
    "modTime": "2024-10-20T16:26:09.8064791+02:00",
    "path": "cmd\\ontology\\main.go"
  },
  {
    "name": "root.go",
    "content": "package ontology\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"os\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n\t\"github.com/chrlesur/Ontology/internal/pipeline\"\r\n\t\"github.com/spf13/cobra\"\r\n\t\"github.com/spf13/viper\"\r\n)\r\n\r\nvar (\r\n\tcfgFile   string\r\n\tinputFile string\r\n\tpasses    int\r\n\tontology  string\r\n)\r\n\r\nvar rootCmd = \u0026cobra.Command{\r\n\tUse:   \"ontology\",\r\n\tShort: i18n.GetMessage(\"RootCmdShort\"),\r\n\tLong:  i18n.GetMessage(\"RootCmdLong\"),\r\n\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\tp, err := pipeline.NewPipeline()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn p.ExecutePipeline(inputFile, passes, ontology)\r\n\t},\r\n}\r\n\r\nfunc Execute() {\r\n\tif err := rootCmd.Execute(); err != nil {\r\n\t\tfmt.Println(err)\r\n\t\tos.Exit(1)\r\n\t}\r\n}\r\n\r\nfunc init() {\r\n\tcobra.OnInitialize(initConfig)\r\n\r\n\trootCmd.PersistentFlags().StringVar(\u0026cfgFile, \"config\", \"\", i18n.GetMessage(\"ConfigFlagUsage\"))\r\n\trootCmd.PersistentFlags().StringVar(\u0026inputFile, \"input\", \"\", i18n.GetMessage(\"InputFlagUsage\"))\r\n\trootCmd.PersistentFlags().IntVar(\u0026passes, \"passes\", 1, i18n.GetMessage(\"PassesFlagUsage\"))\r\n\trootCmd.PersistentFlags().StringVar(\u0026ontology, \"ontology\", \"\", i18n.GetMessage(\"OntologyFlagUsage\"))\r\n\trootCmd.PersistentFlags().BoolVar(\u0026config.GetConfig().ExportRDF, \"rdf\", false, i18n.GetMessage(\"RDFFlagUsage\"))\r\n\trootCmd.PersistentFlags().BoolVar(\u0026config.GetConfig().ExportOWL, \"owl\", false, i18n.GetMessage(\"OWLFlagUsage\"))\r\n\trootCmd.MarkFlagRequired(\"input\")\r\n}\r\n\r\nfunc initConfig() {\r\n\tif cfgFile != \"\" {\r\n\t\t// Use config file from the flag.\r\n\t\tviper.SetConfigFile(cfgFile)\r\n\t} else {\r\n\t\t// Search config in home directory with name \".ontology\" (without extension).\r\n\t\tviper.AddConfigPath(\".\")\r\n\t\tviper.SetConfigName(\".ontology\")\r\n\t}\r\n\r\n\tviper.AutomaticEnv() // read in environment variables that match\r\n\r\n\t// If a config file is found, read it in.\r\n\tif err := viper.ReadInConfig(); err == nil {\r\n\t\tfmt.Println(\"Using config file:\", viper.ConfigFileUsed())\r\n\t}\r\n\r\n\t// Initialize logger\r\n\tlogLevel := viper.GetString(\"log_level\")\r\n\tif logLevel == \"\" {\r\n\t\tlogLevel = \"info\"\r\n\t}\r\n\tlogger.SetLevel(logger.ParseLevel(logLevel))\r\n\r\n\t// Initialize other configurations\r\n\tconfig.InitConfig(viper.GetViper())\r\n}\r\n",
    "size": 2276,
    "modTime": "2024-10-20T16:39:58.4126091+02:00",
    "path": "cmd\\ontology\\root.go"
  },
  {
    "name": "root_test.go",
    "content": "package ontology\r\n\r\nimport (\r\n\t\"testing\"\r\n\r\n\t\"github.com/spf13/cobra\"\r\n)\r\n\r\nfunc TestRootCommand(t *testing.T) {\r\n\tcmd := \u0026cobra.Command{Use: \"root\"}\r\n\tcmd.AddCommand(rootCmd)\r\n\r\n\terr := cmd.Execute()\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Unexpected error executing root command: %v\", err)\r\n\t}\r\n}\r\n\r\nfunc TestEnrichCommand(t *testing.T) {\r\n\tcmd := \u0026cobra.Command{Use: \"root\"}\r\n\tcmd.AddCommand(enrichCmd)\r\n\r\n\t// Test with missing required flags\r\n\terr := cmd.Execute()\r\n\tif err == nil {\r\n\t\tt.Error(\"Expected error due to missing required flags, but got none\")\r\n\t}\r\n\r\n\t// Test with required flags\r\n\tcmd.SetArgs([]string{\"enrich\", \"--input\", \"test.txt\", \"--output\", \"out.txt\"})\r\n\terr = cmd.Execute()\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Unexpected error executing enrich command: %v\", err)\r\n\t}\r\n}\r\n",
    "size": 781,
    "modTime": "2024-10-20T12:25:46.8635116+02:00",
    "path": "cmd\\ontology\\root_test.go"
  },
  {
    "name": "config.yaml",
    "content": "base_uri: \"http://www.wikidata.org/entity/\"\r\nopenai_api_url: \"https://api.openai.com/v1/chat/completions\"\r\nclaude_api_url: \"https://api.anthropic.com/v1/messages\"\r\nollama_api_url: \"http://localhost:11434/api/generate\"\r\nlog_directory: \"logs\"\r\nlog_level: \"info\"\r\nmax_tokens: 8000\r\ncontext_size: 4000\r\ndefault_llm: \"claude\"\r\ndefault_model: \"claude-3-5-sonnet-20240620\"",
    "size": 365,
    "modTime": "2024-10-20T16:25:36.101444+02:00",
    "path": "config.yaml"
  },
  {
    "name": "config.go",
    "content": "package config\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"log\"\r\n\t\"os\"\r\n\t\"sync\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"gopkg.in/yaml.v2\"\r\n)\r\n\r\nvar (\r\n\tonce     sync.Once\r\n\tinstance *Config\r\n)\r\n\r\n// Config structure definition\r\ntype Config struct {\r\n\tBaseURI      string `yaml:\"base_uri\"`\r\n\tOpenAIAPIURL string `yaml:\"openai_api_url\"`\r\n\tClaudeAPIURL string `yaml:\"claude_api_url\"`\r\n\tOllamaAPIURL string `yaml:\"ollama_api_url\"`\r\n\tOpenAIAPIKey string `yaml:\"openai_api_key\"`\r\n\tClaudeAPIKey string `yaml:\"claude_api_key\"`\r\n\tLogDirectory string `yaml:\"log_directory\"`\r\n\tLogLevel     string `yaml:\"log_level\"`\r\n\tMaxTokens    int    `yaml:\"max_tokens\"`\r\n\tContextSize  int    `yaml:\"context_size\"`\r\n\tDefaultLLM   string `yaml:\"default_llm\"`\r\n\tDefaultModel string `yaml:\"default_model\"`\r\n\tOntologyName string `yaml:\"ontology_name\"`\r\n\tExportRDF    bool   `yaml:\"export_rdf\"`\r\n\tExportOWL    bool   `yaml:\"export_owl\"`\r\n}\r\n\r\n// GetConfig returns the singleton instance of Config\r\nfunc GetConfig() *Config {\r\n\tonce.Do(func() {\r\n\t\tinstance = \u0026Config{\r\n\t\t\tOpenAIAPIURL: \"https://api.openai.com/v1/chat/completions\",\r\n\t\t\tClaudeAPIURL: \"https://api.anthropic.com/v1/messages\",\r\n\t\t\tOllamaAPIURL: \"http://localhost:11434/api/generate\",\r\n\t\t\tBaseURI:      \"http://www.wikidata.org/entity/\",\r\n\t\t\tLogDirectory: \"logs\",\r\n\t\t\tLogLevel:     \"info\",\r\n\t\t\tMaxTokens:    4000,\r\n\t\t\tContextSize:  500,\r\n\t\t\tDefaultLLM:   \"openai\",\r\n\t\t\tDefaultModel: \"gpt-3.5-turbo\",\r\n\t\t}\r\n\t\tinstance.loadConfigFile()\r\n\t\tinstance.loadEnvVariables()\r\n\t})\r\n\treturn instance\r\n}\r\n\r\n// loadConfigFile loads the configuration from a YAML file\r\nfunc (c *Config) loadConfigFile() {\r\n\tconfigPath := os.Getenv(\"ONTOLOGY_CONFIG_PATH\")\r\n\tif configPath == \"\" {\r\n\t\tconfigPath = \"config.yaml\"\r\n\t}\r\n\r\n\tdata, err := ioutil.ReadFile(configPath)\r\n\tif err != nil {\r\n\t\tlog.Printf(i18n.GetMessage(\"ErrReadConfigFile\"), err)\r\n\t\treturn\r\n\t}\r\n\r\n\terr = yaml.Unmarshal(data, c)\r\n\tif err != nil {\r\n\t\tlog.Printf(i18n.GetMessage(\"ErrParseConfigFile\"), err)\r\n\t}\r\n}\r\n\r\n// loadEnvVariables loads configuration from environment variables\r\nfunc (c *Config) loadEnvVariables() {\r\n\tif apiKey := os.Getenv(\"OPENAI_API_KEY\"); apiKey != \"\" {\r\n\t\tc.OpenAIAPIKey = apiKey\r\n\t}\r\n\tif apiKey := os.Getenv(\"CLAUDE_API_KEY\"); apiKey != \"\" {\r\n\t\tc.ClaudeAPIKey = apiKey\r\n\t}\r\n\t// Add more environment variables as needed\r\n}\r\n\r\n// ValidateConfig checks if the configuration is valid\r\nfunc (c *Config) ValidateConfig() error {\r\n\tif c.OpenAIAPIKey == \"\" \u0026\u0026 c.ClaudeAPIKey == \"\" {\r\n\t\treturn fmt.Errorf(i18n.GetMessage(\"ErrNoAPIKeys\"))\r\n\t}\r\n\t// Add more validation checks as needed\r\n\treturn nil\r\n}\r\n\r\n// Reload reloads the configuration from file and environment variables\r\nfunc (c *Config) Reload() error {\r\n\tc.loadConfigFile()\r\n\tc.loadEnvVariables()\r\n\treturn c.ValidateConfig()\r\n}\r\n",
    "size": 2780,
    "modTime": "2024-10-20T16:53:44.6093061+02:00",
    "path": "internal\\config\\config.go"
  },
  {
    "name": "convert.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"bytes\"\r\n\t\"fmt\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n\r\n// Convert converts a document segment into QuickStatement format\r\nfunc (qsc *QuickStatementConverter) Convert(segment []byte, context string, ontology string) (string, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ConvertStarted\"))\r\n\r\n\tstatements, err := qsc.parseSegment(segment)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.GetMessage(\"FailedToParseSegment\"), err)\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToParseSegment\"), err)\r\n\t}\r\n\r\n\tenrichedStatements, err := qsc.applyContextAndOntology(statements, context, ontology)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.GetMessage(\"FailedToApplyContextAndOntology\"), err)\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToApplyContextAndOntology\"), err)\r\n\t}\r\n\r\n\tresult, err := qsc.toQuickStatementTSV(enrichedStatements)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.GetMessage(\"FailedToConvertToQuickStatementTSV\"), err)\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToConvertToQuickStatementTSV\"), err)\r\n\t}\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ConvertFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) parseSegment(segment []byte) ([]Statement, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ParsingSegment\"))\r\n\tvar statements []Statement\r\n\tscanner := bufio.NewScanner(bytes.NewReader(segment))\r\n\tfor scanner.Scan() {\r\n\t\tline := scanner.Text()\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif len(parts) \u003c 3 {\r\n\t\t\treturn nil, fmt.Errorf(i18n.GetMessage(\"InvalidSegmentFormat\"))\r\n\t\t}\r\n\t\tstatement := Statement{\r\n\t\t\tSubject:  Entity{ID: parts[0]},\r\n\t\t\tProperty: Property{ID: parts[1]},\r\n\t\t\tObject:   parts[2],\r\n\t\t}\r\n\t\tstatements = append(statements, statement)\r\n\t}\r\n\tif err := scanner.Err(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorScanningSegment\"), err)\r\n\t}\r\n\treturn statements, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) applyContextAndOntology(statements []Statement, context string, ontology string) ([]Statement, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ApplyingContextAndOntology\"))\r\n\t// This is a placeholder implementation. In a real-world scenario, this function would\r\n\t// use the context and ontology to enrich the statements.\r\n\tfor i := range statements {\r\n\t\tstatements[i].Subject.Label = fmt.Sprintf(\"%s (from context)\", statements[i].Subject.ID)\r\n\t}\r\n\treturn statements, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) toQuickStatementTSV(statements []Statement) (string, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ConvertingToQuickStatementTSV\"))\r\n\tvar buffer bytes.Buffer\r\n\tfor _, stmt := range statements {\r\n\t\tline := fmt.Sprintf(\"%s\\t%s\\t%v\\n\", stmt.Subject.ID, stmt.Property.ID, stmt.Object)\r\n\t\t_, err := buffer.WriteString(line)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorWritingQuickStatement\"), err)\r\n\t\t}\r\n\t}\r\n\treturn buffer.String(), nil\r\n}\r\n",
    "size": 2909,
    "modTime": "2024-10-20T14:43:19.3992293+02:00",
    "path": "internal\\converter\\convert.go"
  },
  {
    "name": "logger.go",
    "content": "package converter\r\n\r\nimport (\r\n    \"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\nvar log = logger.GetLogger()",
    "size": 116,
    "modTime": "2024-10-20T14:40:18.8000271+02:00",
    "path": "internal\\converter\\logger.go"
  },
  {
    "name": "owl.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"bytes\"\r\n\t\"fmt\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// ConvertToOWL converts a QuickStatement to OWL format\r\nfunc (qsc *QuickStatementConverter) ConvertToOWL(quickstatement string) (string, error) {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertToOWLStarted\"))\r\n\r\n\tstatements, err := qsc.parseQuickStatement(quickstatement)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToParseQuickStatement\"), err)\r\n\t}\r\n\r\n\tvar owlStatements []string\r\n\tfor _, stmt := range statements {\r\n\t\towlStmt, err := qsc.statementToOWL(stmt)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToConvertStatementToOWL\"), err)\r\n\t\t}\r\n\t\towlStatements = append(owlStatements, owlStmt)\r\n\t}\r\n\r\n\tresult := qsc.generateOWLDocument(owlStatements)\r\n\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertToOWLFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) parseQuickStatement(quickstatement string) ([]Statement, error) {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ParsingQuickStatement\"))\r\n\tvar statements []Statement\r\n\tscanner := bufio.NewScanner(strings.NewReader(quickstatement))\r\n\tfor scanner.Scan() {\r\n\t\tline := scanner.Text()\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif len(parts) \u003c 3 {\r\n\t\t\treturn nil, fmt.Errorf(i18n.GetMessage(\"InvalidQuickStatementFormat\"))\r\n\t\t}\r\n\t\tstatement := Statement{\r\n\t\t\tSubject:  Entity{ID: parts[0]},\r\n\t\t\tProperty: Property{ID: parts[1]},\r\n\t\t\tObject:   parts[2],\r\n\t\t}\r\n\t\tstatements = append(statements, statement)\r\n\t}\r\n\tif err := scanner.Err(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorScanningQuickStatement\"), err)\r\n\t}\r\n\treturn statements, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) statementToOWL(statement Statement) (string, error) {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertingStatementToOWL\"))\r\n\tsubjectURI := fmt.Sprintf(\":%s\", statement.Subject.ID)\r\n\tpropertyURI := fmt.Sprintf(\":%s\", statement.Property.ID)\r\n\tobjectValue := statement.Object.(string) // Type assertion, be cautious in real implementation\r\n\r\n\tvar owlStatement string\r\n\tif strings.HasPrefix(objectValue, \"Q\") {\r\n\t\t// If object is an entity\r\n\t\tobjectURI := fmt.Sprintf(\":%s\", objectValue)\r\n\t\towlStatement = fmt.Sprintf(\"ObjectPropertyAssertion(%s %s %s)\", propertyURI, subjectURI, objectURI)\r\n\t} else {\r\n\t\t// If object is a literal\r\n\t\towlStatement = fmt.Sprintf(\"DataPropertyAssertion(%s %s \\\"%s\\\"^^xsd:string)\", propertyURI, subjectURI, objectValue)\r\n\t}\r\n\r\n\treturn owlStatement, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) generateOWLDocument(owlStatements []string) string {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"GeneratingOWLDocument\"))\r\n\tvar buffer bytes.Buffer\r\n\r\n\tbuffer.WriteString(\"Prefix(:=\u003c\" + config.GetConfig().BaseURI + \"\u003e)\\n\")\r\n\tbuffer.WriteString(\"Prefix(owl:=\u003chttp://www.w3.org/2002/07/owl#\u003e)\\n\")\r\n\tbuffer.WriteString(\"Prefix(rdf:=\u003chttp://www.w3.org/1999/02/22-rdf-syntax-ns#\u003e)\\n\")\r\n\tbuffer.WriteString(\"Prefix(xml:=\u003chttp://www.w3.org/XML/1998/namespace\u003e)\\n\")\r\n\tbuffer.WriteString(\"Prefix(xsd:=\u003chttp://www.w3.org/2001/XMLSchema#\u003e)\\n\")\r\n\tbuffer.WriteString(\"Prefix(rdfs:=\u003chttp://www.w3.org/2000/01/rdf-schema#\u003e)\\n\\n\")\r\n\tbuffer.WriteString(\"Ontology(\u003c\" + config.GetConfig().BaseURI + \"\u003e\\n\\n\")\r\n\r\n\tfor _, stmt := range owlStatements {\r\n\t\tbuffer.WriteString(stmt + \"\\n\")\r\n\t}\r\n\r\n\tbuffer.WriteString(\")\")\r\n\r\n\treturn buffer.String()\r\n}\r\n",
    "size": 3438,
    "modTime": "2024-10-20T16:47:48.1038854+02:00",
    "path": "internal\\converter\\owl.go"
  },
  {
    "name": "parse.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"encoding/xml\"\r\n\t\"fmt\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/knakk/rdf\"\r\n)\r\n\r\n// ParseOntology parses an ontology string and returns a structured representation\r\nfunc ParseOntology(ontology string) (map[string]interface{}, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ParseOntologyStarted\"))\r\n\r\n\tformat := detectOntologyFormat(ontology)\r\n\tvar result map[string]interface{}\r\n\tvar err error\r\n\r\n\tswitch format {\r\n\tcase \"QuickStatement\":\r\n\t\tresult, err = parseQuickStatementOntology(ontology)\r\n\tcase \"RDF\":\r\n\t\tresult, err = parseRDFOntology(ontology)\r\n\tcase \"OWL\":\r\n\t\tresult, err = parseOWLOntology(ontology)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(i18n.GetMessage(\"UnknownOntologyFormat\"))\r\n\t}\r\n\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToParseOntology\"), err)\r\n\t}\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ParseOntologyFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc detectOntologyFormat(ontology string) string {\r\n\tif strings.Contains(ontology, \"Q\") \u0026\u0026 strings.Contains(ontology, \"P\") \u0026\u0026 strings.Contains(ontology, \"\\t\") {\r\n\t\treturn \"QuickStatement\"\r\n\t}\r\n\tif strings.Contains(ontology, \"\u003crdf:RDF\") {\r\n\t\treturn \"RDF\"\r\n\t}\r\n\tif strings.Contains(ontology, \"\u003cOntology\") {\r\n\t\treturn \"OWL\"\r\n\t}\r\n\treturn \"Unknown\"\r\n}\r\n\r\nfunc parseQuickStatementOntology(ontology string) (map[string]interface{}, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ParseQuickStatementOntologyStarted\"))\r\n\r\n\tresult := make(map[string]interface{})\r\n\tentities := make(map[string]map[string]interface{})\r\n\r\n\tlines := strings.Split(ontology, \"\\n\")\r\n\tfor _, line := range lines {\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif len(parts) != 3 {\r\n\t\t\treturn nil, fmt.Errorf(i18n.GetMessage(\"InvalidQuickStatementLine\"))\r\n\t\t}\r\n\r\n\t\tsubject, predicate, object := parts[0], parts[1], parts[2]\r\n\t\tif _, exists := entities[subject]; !exists {\r\n\t\t\tentities[subject] = make(map[string]interface{})\r\n\t\t}\r\n\t\tentities[subject][predicate] = object\r\n\t}\r\n\r\n\tresult[\"entities\"] = entities\r\n\tlog.Debug(i18n.GetMessage(\"ParseQuickStatementOntologyFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc parseRDFOntology(ontology string) (map[string]interface{}, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ParseRDFOntologyStarted\"))\r\n\r\n\tresult := make(map[string]interface{})\r\n\tentities := make(map[string]map[string]interface{})\r\n\r\n\tdec := rdf.NewTripleDecoder(strings.NewReader(ontology), rdf.RDFXML)\r\n\tfor {\r\n\t\ttriple, err := dec.Decode()\r\n\t\tif err != nil {\r\n\t\t\tif err.Error() == \"EOF\" {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorDecodingRDF\"), err)\r\n\t\t}\r\n\r\n\t\tsubject := triple.Subj.String()\r\n\t\tpredicate := triple.Pred.String()\r\n\t\tobject := triple.Obj.String()\r\n\r\n\t\tif _, exists := entities[subject]; !exists {\r\n\t\t\tentities[subject] = make(map[string]interface{})\r\n\t\t}\r\n\t\tentities[subject][predicate] = object\r\n\t}\r\n\r\n\tresult[\"entities\"] = entities\r\n\tlog.Debug(i18n.GetMessage(\"ParseRDFOntologyFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc parseOWLOntology(ontology string) (map[string]interface{}, error) {\r\n\tlog.Debug(i18n.GetMessage(\"ParseOWLOntologyStarted\"))\r\n\r\n\tresult := make(map[string]interface{})\r\n\r\n\t// Simplified OWL parsing\r\n\tvar owlData struct {\r\n\t\tXMLName xml.Name `xml:\"Ontology\"`\r\n\t\tClasses []struct {\r\n\t\t\tIRI   string `xml:\"IRI,attr\"`\r\n\t\t\tLabel string `xml:\"label,attr\"`\r\n\t\t} `xml:\"Declaration\u003eClass\"`\r\n\t}\r\n\r\n\terr := xml.Unmarshal([]byte(ontology), \u0026owlData)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorParsingOWL\"), err)\r\n\t}\r\n\r\n\tclasses := make(map[string]interface{})\r\n\tfor _, class := range owlData.Classes {\r\n\t\tclasses[class.IRI] = map[string]interface{}{\r\n\t\t\t\"label\": class.Label,\r\n\t\t}\r\n\t}\r\n\tresult[\"classes\"] = classes\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ParseOWLOntologyFinished\"))\r\n\treturn result, nil\r\n}\r\n",
    "size": 3787,
    "modTime": "2024-10-20T14:19:06.7515729+02:00",
    "path": "internal\\converter\\parse.go"
  },
  {
    "name": "quickstatement.go",
    "content": "// Package converter provides functionality for converting document segments\r\n// into QuickStatement format and other ontology representations.\r\npackage converter\r\n\r\nimport (\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\n// Converter defines the interface for QuickStatement conversion\r\ntype Converter interface {\r\n\tConvert(segment []byte, context string, ontology string) (string, error)\r\n\tConvertToRDF(quickstatement string) (string, error)\r\n\tConvertToOWL(quickstatement string) (string, error)\r\n}\r\n\r\n// QuickStatementConverter implements the Converter interface\r\ntype QuickStatementConverter struct {\r\n\tlogger *logger.Logger\r\n}\r\n\r\n// NewQuickStatementConverter creates a new QuickStatementConverter\r\nfunc NewQuickStatementConverter(log *logger.Logger) *QuickStatementConverter {\r\n\treturn \u0026QuickStatementConverter{\r\n\t\tlogger: log,\r\n\t}\r\n}\r\n\r\n// Entity represents a Wikibase entity\r\ntype Entity struct {\r\n\tID    string\r\n\tLabel string\r\n}\r\n\r\n// Property represents a Wikibase property\r\ntype Property struct {\r\n\tID       string\r\n\tDataType string\r\n}\r\n\r\n// Statement represents a complete QuickStatement\r\ntype Statement struct {\r\n\tSubject  Entity\r\n\tProperty Property\r\n\tObject   interface{}\r\n}\r\n",
    "size": 1198,
    "modTime": "2024-10-20T16:53:22.8837516+02:00",
    "path": "internal\\converter\\quickstatement.go"
  },
  {
    "name": "rdf.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"bytes\"\r\n\t\"fmt\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// ConvertToRDF converts a QuickStatement to RDF format\r\nfunc (qsc *QuickStatementConverter) ConvertToRDF(quickstatement string) (string, error) {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertToRDFStarted\"))\r\n\r\n\tstatements, err := qsc.parseQuickStatement(quickstatement)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToParseQuickStatement\"), err)\r\n\t}\r\n\r\n\tvar rdfStatements []string\r\n\tfor _, stmt := range statements {\r\n\t\trdfStmt, err := qsc.statementToRDF(stmt)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"FailedToConvertStatementToRDF\"), err)\r\n\t\t}\r\n\t\trdfStatements = append(rdfStatements, rdfStmt)\r\n\t}\r\n\r\n\tresult := qsc.generateRDFDocument(rdfStatements)\r\n\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertToRDFFinished\"))\r\n\treturn result, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) parseQuickStatementForRDF(quickstatement string) ([]Statement, error) {\tqsc.logger.Debug(i18n.GetMessage(\"ParsingQuickStatement\"))\r\n\tvar statements []Statement\r\n\tscanner := bufio.NewScanner(strings.NewReader(quickstatement))\r\n\tfor scanner.Scan() {\r\n\t\tline := scanner.Text()\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif len(parts) \u003c 3 {\r\n\t\t\treturn nil, fmt.Errorf(i18n.GetMessage(\"InvalidQuickStatementFormat\"))\r\n\t\t}\r\n\t\tstatement := Statement{\r\n\t\t\tSubject:  Entity{ID: parts[0]},\r\n\t\t\tProperty: Property{ID: parts[1]},\r\n\t\t\tObject:   parts[2],\r\n\t\t}\r\n\t\tstatements = append(statements, statement)\r\n\t}\r\n\tif err := scanner.Err(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorScanningQuickStatement\"), err)\r\n\t}\r\n\treturn statements, nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) statementToRDF(statement Statement) (string, error) {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"ConvertingStatementToRDF\"))\r\n\tsubjectURI := fmt.Sprintf(\"\u003c%s%s\u003e\", config.GetConfig().BaseURI, statement.Subject.ID)\r\n\tpropertyURI := fmt.Sprintf(\"\u003c%s%s\u003e\", config.GetConfig().BaseURI, statement.Property.ID)\r\n\tobjectValue := statement.Object.(string) // Type assertion, be cautious in real implementation\r\n\r\n\tvar objectRDF string\r\n\tif strings.HasPrefix(objectValue, \"Q\") {\r\n\t\t// If object is an entity\r\n\t\tobjectRDF = fmt.Sprintf(\"\u003c%s%s\u003e\", config.GetConfig().BaseURI, objectValue)\r\n\t} else {\r\n\t\t// If object is a literal\r\n\t\tobjectRDF = fmt.Sprintf(\"\\\"%s\\\"\", objectValue)\r\n\t}\r\n\r\n\treturn fmt.Sprintf(\"%s %s %s .\", subjectURI, propertyURI, objectRDF), nil\r\n}\r\n\r\nfunc (qsc *QuickStatementConverter) generateRDFDocument(rdfStatements []string) string {\r\n\tqsc.logger.Debug(i18n.GetMessage(\"GeneratingRDFDocument\"))\r\n\tvar buffer bytes.Buffer\r\n\r\n\tbuffer.WriteString(\"@prefix wd: \u003c\" + config.GetConfig().BaseURI + \"\u003e .\\n\\n\")\r\n\tfor _, stmt := range rdfStatements {\r\n\t\tbuffer.WriteString(stmt + \"\\n\")\r\n\t}\r\n\r\n\treturn buffer.String()\r\n}\r\n",
    "size": 2918,
    "modTime": "2024-10-20T16:48:49.518701+02:00",
    "path": "internal\\converter\\rdf.go"
  },
  {
    "name": "utils.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"crypto/rand\"\r\n\t\"fmt\"\r\n\t\"net/url\"\r\n\t\"strings\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// EscapeString escapes special characters in a string for safe use in output formats\r\nfunc EscapeString(s string) string {\r\n\treturn strings.NewReplacer(\r\n\t\t`\"`, `\\\"`,\r\n\t\t`\\`, `\\\\`,\r\n\t\t`/`, `\\/`,\r\n\t\t\"\\b\", `\\b`,\r\n\t\t\"\\f\", `\\f`,\r\n\t\t\"\\n\", `\\n`,\r\n\t\t\"\\r\", `\\r`,\r\n\t\t\"\\t\", `\\t`,\r\n\t).Replace(s)\r\n}\r\n\r\n// IsValidURI checks if a string is a valid URI\r\nfunc IsValidURI(uri string) bool {\r\n\t_, err := url.ParseRequestURI(uri)\r\n\tif err != nil {\r\n\t\tlog.Debug(i18n.GetMessage(\"InvalidURI\")) // Cette ligne est correcte car log.Debug n'attend qu'un seul argument\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}\r\n\r\n// FormatDate formats a date string to a standard format (ISO 8601)\r\nfunc FormatDate(date string) (string, error) {\r\n\tparsedDate, err := time.Parse(time.RFC3339, date)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.GetMessage(\"InvalidDateFormat\"), err) // Ajout de l'erreur comme second argument\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrorParsingDate\"), err)\r\n\t}\r\n\treturn parsedDate.Format(time.RFC3339), nil\r\n}\r\n\r\n// GenerateUniqueID generates a unique identifier for entities without one\r\nfunc GenerateUniqueID() string {\r\n\tb := make([]byte, 16)\r\n\t_, err := rand.Read(b)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.GetMessage(\"ErrorGeneratingUniqueID\"), err)\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%x\", b)\r\n}\r\n\r\n// SplitIntoChunks divides a large dataset into smaller chunks for batch processing\r\nfunc SplitIntoChunks(data []byte, chunkSize int) [][]byte {\r\n\tvar chunks [][]byte\r\n\tfor i := 0; i \u003c len(data); i += chunkSize {\r\n\t\tend := i + chunkSize\r\n\t\tif end \u003e len(data) {\r\n\t\t\tend = len(data)\r\n\t\t}\r\n\t\tchunks = append(chunks, data[i:end])\r\n\t}\r\n\treturn chunks\r\n}\r\n\r\n// MergeMaps merges multiple maps into a single map\r\nfunc MergeMaps(maps ...map[string]interface{}) map[string]interface{} {\r\n\tresult := make(map[string]interface{})\r\n\tfor _, m := range maps {\r\n\t\tfor k, v := range m {\r\n\t\t\tresult[k] = v\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}\r\n\r\n// TruncateString truncates a string to a specified length, adding an ellipsis if truncated\r\nfunc TruncateString(s string, maxLength int) string {\r\n\tif len(s) \u003c= maxLength {\r\n\t\treturn s\r\n\t}\r\n\treturn s[:maxLength-3] + \"...\"\r\n}\r\n\r\n// NormalizeWhitespace removes extra whitespace from a string\r\nfunc NormalizeWhitespace(s string) string {\r\n\treturn strings.Join(strings.Fields(s), \" \")\r\n}\r\n\r\n// IsNumeric checks if a string contains only numeric characters\r\nfunc IsNumeric(s string) bool {\r\n\tfor _, r := range s {\r\n\t\tif r \u003c '0' || r \u003e '9' {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}\r\n",
    "size": 2639,
    "modTime": "2024-10-20T14:44:56.9267011+02:00",
    "path": "internal\\converter\\utils.go"
  },
  {
    "name": "validate.go",
    "content": "package converter\r\n\r\nimport (\r\n\t\"bufio\"\r\n\t\"fmt\"\r\n\t\"regexp\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// ValidateQuickStatement validates a QuickStatement string\r\nfunc ValidateQuickStatement(statement string) bool {\r\n\tlog.Debug(i18n.GetMessage(\"ValidateQuickStatementStarted\"))\r\n\r\n\terr := validateQuickStatementSyntax(statement)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.GetMessage(\"InvalidQuickStatementSyntax\"), err)\r\n\t\treturn false\r\n\t}\r\n\r\n\terr = checkEntityReferences(statement)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.GetMessage(\"InvalidEntityReferences\"), err)\r\n\t\treturn false\r\n\t}\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ValidateQuickStatementFinished\"))\r\n\treturn true\r\n}\r\n\r\n// ValidateRDF validates an RDF string\r\nfunc ValidateRDF(rdf string) bool {\r\n\tlog.Debug(i18n.GetMessage(\"ValidateRDFStarted\"))\r\n\r\n\terr := validateRDFSyntax(rdf)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.GetMessage(\"InvalidRDFSyntax\"), err)\r\n\t\treturn false\r\n\t}\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ValidateRDFFinished\"))\r\n\treturn true\r\n}\r\n\r\n// ValidateOWL validates an OWL string\r\nfunc ValidateOWL(owl string) bool {\r\n\tlog.Debug(i18n.GetMessage(\"ValidateOWLStarted\"))\r\n\r\n\terr := validateOWLSyntax(owl)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.GetMessage(\"InvalidOWLSyntax\"), err)\r\n\t\treturn false\r\n\t}\r\n\r\n\tlog.Debug(i18n.GetMessage(\"ValidateOWLFinished\"))\r\n\treturn true\r\n}\r\n\r\nfunc validateQuickStatementSyntax(statement string) error {\r\n\tscanner := bufio.NewScanner(strings.NewReader(statement))\r\n\tlineNum := 0\r\n\tfor scanner.Scan() {\r\n\t\tlineNum++\r\n\t\tline := scanner.Text()\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif len(parts) != 3 {\r\n\t\t\treturn fmt.Errorf(i18n.GetMessage(\"InvalidQuickStatementLine\"), lineNum)\r\n\t\t}\r\n\t\tif !isValidEntity(parts[0]) || !isValidProperty(parts[1]) {\r\n\t\t\treturn fmt.Errorf(i18n.GetMessage(\"InvalidEntityOrProperty\"), lineNum)\r\n\t\t}\r\n\t}\r\n\treturn scanner.Err()\r\n}\r\n\r\nfunc validateRDFSyntax(rdf string) error {\r\n\tif !strings.Contains(rdf, \"\u003crdf:RDF\") || !strings.Contains(rdf, \"\u003c/rdf:RDF\u003e\") {\r\n\t\treturn fmt.Errorf(i18n.GetMessage(\"MissingRDFTags\"))\r\n\t}\r\n\tif !strings.Contains(rdf, \"xmlns:rdf=\\\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\\\"\") {\r\n\t\treturn fmt.Errorf(i18n.GetMessage(\"MissingRDFNamespace\"))\r\n\t}\r\n\treturn nil\r\n}\r\n\r\nfunc validateOWLSyntax(owl string) error {\r\n\tif !strings.Contains(owl, \"\u003cowl:Ontology\") || !strings.Contains(owl, \"\u003c/owl:Ontology\u003e\") {\r\n\t\treturn fmt.Errorf(i18n.GetMessage(\"MissingOWLTags\"))\r\n\t}\r\n\tif !strings.Contains(owl, \"xmlns:owl=\\\"http://www.w3.org/2002/07/owl#\\\"\") {\r\n\t\treturn fmt.Errorf(i18n.GetMessage(\"MissingOWLNamespace\"))\r\n\t}\r\n\treturn nil\r\n}\r\n\r\nfunc checkEntityReferences(statement string) error {\r\n\tscanner := bufio.NewScanner(strings.NewReader(statement))\r\n\tlineNum := 0\r\n\tfor scanner.Scan() {\r\n\t\tlineNum++\r\n\t\tline := scanner.Text()\r\n\t\tparts := strings.Split(line, \"\\t\")\r\n\t\tif !isValidEntity(parts[0]) {\r\n\t\t\treturn fmt.Errorf(i18n.GetMessage(\"InvalidEntityReference\"), parts[0], lineNum)\r\n\t\t}\r\n\t}\r\n\treturn scanner.Err()\r\n}\r\n\r\nfunc isValidEntity(entity string) bool {\r\n\treturn regexp.MustCompile(`^Q\\d+$`).MatchString(entity)\r\n}\r\n\r\nfunc isValidProperty(property string) bool {\r\n\treturn regexp.MustCompile(`^P\\d+$`).MatchString(property)\r\n}\r\n\r\nfunc isValidURI(uri string) bool {\r\n\t// This is a simplified URI validation. In a real-world scenario, you might want to use a more comprehensive validation.\r\n\treturn regexp.MustCompile(`^(http|https)://`).MatchString(uri)\r\n}\r\n",
    "size": 3409,
    "modTime": "2024-10-20T14:43:44.4003488+02:00",
    "path": "internal\\converter\\validate.go"
  },
  {
    "name": "messages.go",
    "content": "package i18n\r\n\r\nconst (\r\n\tRootCmdShortDesc = \"Ontology enrichment tool\"\r\n\tRootCmdLongDesc  = `Ontology is a command-line tool for enriching ontologies from various document formats.\r\nIt supports multiple input formats and can utilize different language models for analysis.`\r\n\r\n\tEnrichCmdShortDesc = \"Enrich an ontology from input documents\"\r\n\tEnrichCmdLongDesc  = `The enrich command processes input documents to create or update an ontology.\r\nIt can handle various input formats and use different language models for analysis.`\r\n\r\n\tConfigFlagUsage = \"config file (default is $HOME/.ontology.yaml)\"\r\n\tDebugFlagUsage  = \"enable debug mode\"\r\n\tSilentFlagUsage = \"silent mode, only show errors\"\r\n\r\n\tInputFlagUsage     = \"input file or directory\"\r\n\tOutputFlagUsage    = \"output file for the enriched ontology\"\r\n\tFormatFlagUsage    = \"input format (auto-detected if not specified)\"\r\n\tLLMFlagUsage       = \"language model to use for analysis\"\r\n\tLLMModelFlagUsage  = \"specific model for the chosen LLM\"\r\n\tPassesFlagUsage    = \"number of passes for ontology enrichment\"\r\n\tRDFFlagUsage       = \"export ontology in RDF format\"\r\n\tOWLFlagUsage       = \"export ontology in OWL format\"\r\n\tRecursiveFlagUsage = \"process input directory recursively\"\r\n\r\n\tInitializingApplication = \"Initializing Ontology application\"\r\n\tStartingEnrichProcess   = \"Starting ontology enrichment process\"\r\n\tEnrichProcessCompleted  = \"Ontology enrichment process completed\"\r\n\tExecutingPipeline       = \"Executing ontology enrichment pipeline\"\r\n\r\n\tErrorExecutingRootCmd  = \"Error executing root command\"\r\n\tErrorExecutingPipeline = \"Error executing pipeline\"\r\n\tErrUnsupportedModel    = \"unsupported model\"\r\n\tErrAPIKeyMissing       = \"API key is missing\"\r\n\tErrTranslationFailed   = \"translation failed\"\r\n\tErrInvalidLLMType      = \"invalid LLM type\"\r\n\tErrContextTooLong      = \"context is too long\"\r\n\r\n\tTranslationStarted   = \"Translation started\"\r\n\tTranslationRetry     = \"Translation retry\"\r\n\tTranslationCompleted = \"Translation completed\"\r\n\r\n\tErrCreateLogDir = \"Failed to create log directory\"\r\n\tErrOpenLogFile  = \"Failed to open log file\"\r\n\r\n\tParseStarted             = \"Parsing started\"\r\n\tParseFailed              = \"Parsing failed\"\r\n\tParseCompleted           = \"Parsing completed\"\r\n\tMetadataExtractionFailed = \"Metadata extraction failed\"\r\n\tPageParseFailed          = \"Failed to parse page\"\r\n\tTextExtractionFailed     = \"Failed to extract text from page\"\r\n\r\n\tErrInvalidContent          = \"invalid content\"\r\n\tErrTokenization            = \"tokenization error\"\r\n\tErrReadingContent          = \"error reading content\"\r\n\tErrTokenizerInitialization = \"error initializing tokenizer\"\r\n\tErrTokenCounting           = \"error counting tokens\"\r\n\r\n\tLogSegmentationStarted   = \"Segmentation started\"\r\n\tLogSegmentationCompleted = \"Segmentation completed: %d segments\"\r\n\tLogContextGeneration     = \"Generating context\"\r\n\tLogMergingSegments       = \"Merging segments\"\r\n\r\n\tErrReadConfigFile  = \"Failed to read config file: %v\"\r\n    ErrParseConfigFile = \"Failed to parse config file: %v\"\r\n    ErrNoAPIKeys       = \"No API keys provided for any LLM service\"\r\n\r\n\tStartingQuickStatementConversion = \"Starting conversion to QuickStatement format\"\r\n    QuickStatementConversionCompleted = \"QuickStatement conversion completed\"\r\n    StartingRDFConversion = \"Starting conversion to RDF format\"\r\n    RDFConversionCompleted = \"RDF conversion completed\"\r\n    StartingOWLConversion = \"Starting conversion to OWL format\"\r\n    OWLConversionCompleted = \"OWL conversion completed\"\r\n)\r\n\r\nfunc GetMessage(key string) string {\r\n\treturn key // Pour l'instant, on retourne simplement la cl√©\r\n}\r\n",
    "size": 3617,
    "modTime": "2024-10-20T16:44:33.1449854+02:00",
    "path": "internal\\i18n\\messages.go"
  },
  {
    "name": "claude.go",
    "content": "// internal/llm/claude.go\r\n\r\npackage llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// ClaudeClient implements the Client interface for Claude\r\ntype ClaudeClient struct {\r\n\tapiKey string\r\n\tmodel  string\r\n\tclient *http.Client\r\n}\r\n\r\n// supportedClaudeModels defines the list of supported Claude models\r\nvar supportedClaudeModels = map[string]bool{\r\n\t\"claude-3-5-sonnet-20240620\": true,\r\n\t\"claude-3-opus-20240229\":     true,\r\n\t\"claude-3-haiku-20240307\":    true,\r\n}\r\n\r\n// NewClaudeClient creates a new Claude client\r\nfunc NewClaudeClient(apiKey string, model string) (*ClaudeClient, error) {\r\n\tif apiKey == \"\" {\r\n\t\treturn nil, ErrAPIKeyMissing\r\n\t}\r\n\r\n\tif !supportedClaudeModels[model] {\r\n\t\treturn nil, fmt.Errorf(\"%w: %s\", ErrUnsupportedModel, model)\r\n\t}\r\n\r\n\treturn \u0026ClaudeClient{\r\n\t\tapiKey: apiKey,\r\n\t\tmodel:  model,\r\n\t\tclient: \u0026http.Client{Timeout: 30 * time.Second},\r\n\t}, nil\r\n}\r\n\r\n// Translate sends a prompt to the Claude API and returns the response\r\nfunc (c *ClaudeClient) Translate(prompt string, context string) (string, error) {\r\n\tlog.Debug(i18n.TranslationStarted, \"Claude\", c.model)\r\n\r\n\tvar result string\r\n\tvar err error\r\n\tfor attempt := 1; attempt \u003c= 5; attempt++ {\r\n\t\tresult, err = c.makeRequest(prompt, context)\r\n\t\tif err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlog.Warning(i18n.TranslationRetry, attempt, err)\r\n\t\ttime.Sleep(time.Duration(attempt) * time.Second)\r\n\t}\r\n\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%w: %v\", ErrTranslationFailed, err)\r\n\t}\r\n\r\n\tlog.Info(i18n.TranslationCompleted, \"Claude\", c.model)\r\n\treturn result, nil\r\n}\r\n\r\nfunc (c *ClaudeClient) makeRequest(prompt string, context string) (string, error) {\r\n\turl := config.GetConfig().ClaudeAPIURL\r\n\r\n\trequestBody, err := json.Marshal(map[string]interface{}{\r\n\t\t\"model\": c.model,\r\n\t\t\"messages\": []map[string]string{\r\n\t\t\t{\"role\": \"system\", \"content\": context},\r\n\t\t\t{\"role\": \"user\", \"content\": prompt},\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshalling request: %w\", err)\r\n\t}\r\n\r\n\treq, err := http.NewRequest(\"POST\", url, bytes.NewBuffer(requestBody))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\treq.Header.Set(\"x-api-key\", c.apiKey)\r\n\r\n\tresp, err := c.client.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tbody, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error reading response: %w\", err)\r\n\t}\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"API request failed with status code %d: %s\", resp.StatusCode, string(body))\r\n\t}\r\n\r\n\tvar response struct {\r\n\t\tContent []struct {\r\n\t\t\tText string `json:\"text\"`\r\n\t\t} `json:\"content\"`\r\n\t}\r\n\r\n\terr = json.Unmarshal(body, \u0026response)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error unmarshalling response: %w\", err)\r\n\t}\r\n\r\n\tif len(response.Content) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"no content in response\")\r\n\t}\r\n\r\n\treturn response.Content[0].Text, nil\r\n}\r\n",
    "size": 3143,
    "modTime": "2024-10-20T15:51:57.3896849+02:00",
    "path": "internal\\llm\\claude.go"
  },
  {
    "name": "client.go",
    "content": "package llm\r\n\r\n// Client defines the interface for LLM clients\r\ntype Client interface {\r\n    // Translate takes a prompt and context, and returns the LLM's response\r\n    Translate(prompt string, context string) (string, error)\r\n}",
    "size": 229,
    "modTime": "2024-10-20T15:17:59.0271205+02:00",
    "path": "internal\\llm\\client.go"
  },
  {
    "name": "constants.go",
    "content": "// internal/llm/constants.go\r\n\r\npackage llm\r\n\r\nimport \"time\"\r\n\r\n\r\nconst (\r\n    MaxRetries        = 5\r\n    InitialRetryDelay = 1 * time.Second\r\n    MaxRetryDelay     = 32 * time.Second\r\n)\r\n\r\nvar ModelContextLimits = map[string]int{\r\n    \"GPT-4o\":                 8192,\r\n    \"GPT-4o mini\":            4096,\r\n    \"o1-preview\":             16384,\r\n    \"o1-mini\":                2048,\r\n    \"claude-3-5-sonnet-20240620\": 200000,\r\n    \"claude-3-opus-20240229\":     200000,\r\n    \"claude-3-haiku-20240307\":    200000,\r\n    \"llama3.2:3B\":            4096,\r\n    \"llama3.1:8B\":            4096,\r\n    \"mistral-nemo:12B\":       8192,\r\n    \"mixtral:7B\":             32768,\r\n    \"mistral:7B\":             8192,\r\n    \"mistral-small:22B\":      16384,\r\n}",
    "size": 735,
    "modTime": "2024-10-20T15:18:13.4507413+02:00",
    "path": "internal\\llm\\constants.go"
  },
  {
    "name": "errors.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"errors\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\nvar (\r\n\tErrUnsupportedModel  = errors.New(i18n.ErrUnsupportedModel)\r\n\tErrAPIKeyMissing     = errors.New(i18n.ErrAPIKeyMissing)\r\n\tErrTranslationFailed = errors.New(i18n.ErrTranslationFailed)\r\n\tErrInvalidLLMType    = errors.New(i18n.ErrInvalidLLMType)\r\n\tErrContextTooLong    = errors.New(i18n.ErrContextTooLong)\r\n)\r\n",
    "size": 404,
    "modTime": "2024-10-20T15:17:23.2587757+02:00",
    "path": "internal\\llm\\errors.go"
  },
  {
    "name": "factory.go",
    "content": "// internal/llm/factory.go\r\n\r\npackage llm\r\n\r\nimport (\r\n\t\"fmt\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n)\r\n\r\nfunc GetClient(llmType string, model string) (Client, error) {\r\n\tcfg := config.GetConfig()\r\n\r\n\tswitch llmType {\r\n\tcase \"openai\":\r\n\t\treturn NewOpenAIClient(cfg.OpenAIAPIKey, model)\r\n\tcase \"claude\":\r\n\t\treturn NewClaudeClient(cfg.ClaudeAPIKey, model)\r\n\tcase \"ollama\":\r\n\t\treturn NewOllamaClient(model)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"%w: %s\", ErrInvalidLLMType, llmType)\r\n\t}\r\n}\r\n\r\ntype contextCheckingClient struct {\r\n\tbaseClient Client\r\n\tmodel      string\r\n}\r\n\r\nfunc (c *contextCheckingClient) Translate(prompt string, context string) (string, error) {\r\n\tif err := CheckContextLength(c.model, context); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn c.baseClient.Translate(prompt, context)\r\n}\r\n",
    "size": 813,
    "modTime": "2024-10-20T15:27:23.170757+02:00",
    "path": "internal\\llm\\factory.go"
  },
  {
    "name": "logger.go",
    "content": "// internal/llm/logger.go\r\n\r\npackage llm\r\n\r\nimport (\r\n    \"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\nvar log = logger.GetLogger()",
    "size": 139,
    "modTime": "2024-10-20T15:51:39.514526+02:00",
    "path": "internal\\llm\\logger.go"
  },
  {
    "name": "ollama.go",
    "content": "// internal/llm/ollama.go\r\n\r\npackage llm\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"encoding/json\"\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"net/http\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// OllamaClient implements the Client interface for Ollama\r\ntype OllamaClient struct {\r\n\tmodel  string\r\n\tclient *http.Client\r\n}\r\n\r\n// supportedOllamaModels defines the list of supported Ollama models\r\nvar supportedOllamaModels = map[string]bool{\r\n\t\"llama3.2:3B\":       true,\r\n\t\"llama3.1:8B\":       true,\r\n\t\"mistral-nemo:12B\":  true,\r\n\t\"mixtral:7B\":        true,\r\n\t\"mistral:7B\":        true,\r\n\t\"mistral-small:22B\": true,\r\n}\r\n\r\n// NewOllamaClient creates a new Ollama client\r\nfunc NewOllamaClient(model string) (*OllamaClient, error) {\r\n\tif !supportedOllamaModels[model] {\r\n\t\treturn nil, fmt.Errorf(\"%w: %s\", ErrUnsupportedModel, model)\r\n\t}\r\n\r\n\treturn \u0026OllamaClient{\r\n\t\tmodel:  model,\r\n\t\tclient: \u0026http.Client{Timeout: 30 * time.Second},\r\n\t}, nil\r\n}\r\n\r\n// Translate sends a prompt to the Ollama API and returns the response\r\nfunc (c *OllamaClient) Translate(prompt string, context string) (string, error) {\r\n\tlog.Debug(i18n.TranslationStarted, \"Ollama\", c.model)\r\n\r\n\tvar result string\r\n\tvar err error\r\n\tfor attempt := 1; attempt \u003c= 5; attempt++ {\r\n\t\tresult, err = c.makeRequest(prompt, context)\r\n\t\tif err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlog.Warning(i18n.TranslationRetry, attempt, err)\r\n\t\ttime.Sleep(time.Duration(attempt) * time.Second)\r\n\t}\r\n\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%w: %v\", ErrTranslationFailed, err)\r\n\t}\r\n\r\n\tlog.Info(i18n.TranslationCompleted, \"Ollama\", c.model)\r\n\treturn result, nil\r\n}\r\n\r\nfunc (c *OllamaClient) makeRequest(prompt string, context string) (string, error) {\r\n\turl := config.GetConfig().OllamaAPIURL\r\n\r\n\trequestBody, err := json.Marshal(map[string]interface{}{\r\n\t\t\"model\":  c.model,\r\n\t\t\"prompt\": prompt,\r\n\t\t\"system\": context,\r\n\t\t\"stream\": false,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error marshalling request: %w\", err)\r\n\t}\r\n\r\n\treq, err := http.NewRequest(\"POST\", url, bytes.NewBuffer(requestBody))\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating request: %w\", err)\r\n\t}\r\n\r\n\treq.Header.Set(\"Content-Type\", \"application/json\")\r\n\r\n\tresp, err := c.client.Do(req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error sending request: %w\", err)\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\r\n\tbody, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error reading response: %w\", err)\r\n\t}\r\n\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn \"\", fmt.Errorf(\"API request failed with status code %d: %s\", resp.StatusCode, string(body))\r\n\t}\r\n\r\n\tvar response struct {\r\n\t\tResponse string `json:\"response\"`\r\n\t}\r\n\r\n\terr = json.Unmarshal(body, \u0026response)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error unmarshalling response: %w\", err)\r\n\t}\r\n\r\n\treturn response.Response, nil\r\n}\r\n",
    "size": 2857,
    "modTime": "2024-10-20T15:52:01.2505872+02:00",
    "path": "internal\\llm\\ollama.go"
  },
  {
    "name": "openai.go",
    "content": "// internal/llm/openai.go\r\n\r\npackage llm\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"fmt\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/sashabaranov/go-openai\"\r\n)\r\n\r\n// OpenAIClient implements the Client interface for OpenAI\r\ntype OpenAIClient struct {\r\n\tclient *openai.Client\r\n\tmodel  string\r\n}\r\n\r\n// supportedModels defines the list of supported OpenAI models\r\nvar supportedModels = map[string]bool{\r\n\t\"GPT-4o\":      true,\r\n\t\"GPT-4o mini\": true,\r\n\t\"o1-preview\":  true,\r\n\t\"o1-mini\":     true,\r\n}\r\n\r\n\r\n// NewOpenAIClient creates a new OpenAI client\r\nfunc NewOpenAIClient(apiKey string, model string) (*OpenAIClient, error) {\r\n\tif apiKey == \"\" {\r\n\t\treturn nil, ErrAPIKeyMissing\r\n\t}\r\n\r\n\tif !supportedModels[model] {\r\n\t\treturn nil, fmt.Errorf(\"%w: %s\", ErrUnsupportedModel, model)\r\n\t}\r\n\r\n\tclient := openai.NewClient(apiKey)\r\n\treturn \u0026OpenAIClient{\r\n\t\tclient: client,\r\n\t\tmodel:  model,\r\n\t}, nil\r\n}\r\n\r\n// Translate sends a prompt to the OpenAI API and returns the response\r\nfunc (c *OpenAIClient) Translate(prompt string, context string) (string, error) {\r\n\tlog.Debug(i18n.TranslationStarted, \"OpenAI\", c.model)\r\n\r\n\tvar result string\r\n\tvar err error\r\n\tfor attempt := 1; attempt \u003c= 5; attempt++ {\r\n\t\tresult, err = c.makeRequest(prompt, context)\r\n\t\tif err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlog.Warning(i18n.TranslationRetry, attempt, err)\r\n\t\ttime.Sleep(time.Duration(attempt) * time.Second)\r\n\t}\r\n\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%w: %v\", ErrTranslationFailed, err)\r\n\t}\r\n\r\n\tlog.Info(i18n.TranslationCompleted, \"OpenAI\", c.model)\r\n\treturn result, nil\r\n}\r\n\r\nfunc (c *OpenAIClient) makeRequest(prompt string, systemContext string) (string, error) {\r\n\treq := openai.ChatCompletionRequest{\r\n\t\tModel: c.model,\r\n\t\tMessages: []openai.ChatCompletionMessage{\r\n\t\t\t{\r\n\t\t\t\tRole:    openai.ChatMessageRoleSystem,\r\n\t\t\t\tContent: systemContext,\r\n\t\t\t},\r\n\t\t\t{\r\n\t\t\t\tRole:    openai.ChatMessageRoleUser,\r\n\t\t\t\tContent: prompt,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\r\n\tctx := context.Background()\r\n\tresp, err := c.client.CreateChatCompletion(ctx, req)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error creating chat completion: %w\", err)\r\n\t}\r\n\r\n\tif len(resp.Choices) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"no choices in response\")\r\n\t}\r\n\r\n\treturn resp.Choices[0].Message.Content, nil\r\n}\r\n",
    "size": 2244,
    "modTime": "2024-10-20T15:52:03.649678+02:00",
    "path": "internal\\llm\\openai.go"
  },
  {
    "name": "utils.go",
    "content": "package llm\r\n\r\nimport (\r\n\t\"github.com/chrlesur/Ontology/internal/tokenizer\"\r\n)\r\n\r\nfunc CheckContextLength(model string, context string) error {\r\n\tlimit, ok := ModelContextLimits[model]\r\n\tif !ok {\r\n\t\treturn ErrUnsupportedModel\r\n\t}\r\n\r\n\ttokenCount, err := tokenizer.CountTokens(context)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\r\n\tif tokenCount \u003e limit {\r\n\t\treturn ErrContextTooLong\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n",
    "size": 399,
    "modTime": "2024-10-20T15:16:37.2625502+02:00",
    "path": "internal\\llm\\utils.go"
  },
  {
    "name": "logger.go",
    "content": "// internal/logger/logger.go\r\n\r\npackage logger\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io\"\r\n\t\"log\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"runtime\"\r\n\t\"sync\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\n// LogLevel represents the severity of a log message\r\ntype LogLevel int\r\n\r\nconst (\r\n\t// DebugLevel is used for detailed system operations\r\n\tDebugLevel LogLevel = iota\r\n\t// InfoLevel is used for general operational entries\r\n\tInfoLevel\r\n\t// WarningLevel is used for non-critical issues\r\n\tWarningLevel\r\n\t// ErrorLevel is used for errors that need attention\r\n\tErrorLevel\r\n)\r\n\r\nvar (\r\n\tinstance *Logger\r\n\tonce     sync.Once\r\n)\r\n\r\n// Logger handles all logging operations\r\ntype Logger struct {\r\n\tlevel  LogLevel\r\n\tlogger *log.Logger\r\n\tfile   *os.File\r\n\tmu     sync.Mutex\r\n}\r\n\r\n// GetLogger returns the singleton instance of Logger\r\nfunc GetLogger() *Logger {\r\n\tonce.Do(func() {\r\n\t\tinstance = \u0026Logger{\r\n\t\t\tlevel:  InfoLevel,\r\n\t\t\tlogger: log.New(os.Stdout, \"\", log.Ldate|log.Ltime),\r\n\t\t}\r\n\t\tinstance.setupLogFile()\r\n\t})\r\n\treturn instance\r\n}\r\n\r\nfunc (l *Logger) setupLogFile() {\r\n\tlogDir := config.GetConfig().LogDirectory\r\n\tif logDir == \"\" {\r\n\t\tlogDir = \"logs\"\r\n\t}\r\n\r\n\tif err := os.MkdirAll(logDir, 0755); err != nil {\r\n\t\tl.Error(i18n.GetMessage(\"ErrCreateLogDir\"), err)\r\n\t\treturn\r\n\t}\r\n\r\n\tlogFile := filepath.Join(logDir, fmt.Sprintf(\"ontology_%s.log\", time.Now().Format(\"2006-01-02\")))\r\n\tfile, err := os.OpenFile(logFile, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)\r\n\tif err != nil {\r\n\t\tl.Error(i18n.GetMessage(\"ErrOpenLogFile\"), err)\r\n\t\treturn\r\n\t}\r\n\r\n\tl.file = file\r\n\tl.logger.SetOutput(io.MultiWriter(os.Stdout, file))\r\n}\r\n\r\n// SetLevel sets the current log level\r\nfunc (l *Logger) SetLevel(level LogLevel) {\r\n\tl.level = level\r\n}\r\n\r\nfunc (l *Logger) log(level LogLevel, message string, args ...interface{}) {\r\n\tif level \u003c l.level {\r\n\t\treturn\r\n\t}\r\n\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\r\n\t_, file, line, _ := runtime.Caller(2)\r\n\tlogMessage := fmt.Sprintf(\"[%s] %s:%d - %s\", level, filepath.Base(file), line, fmt.Sprintf(message, args...))\r\n\tl.logger.Println(logMessage)\r\n}\r\n\r\n// Debug logs a message at DebugLevel\r\nfunc (l *Logger) Debug(message string, args ...interface{}) {\r\n\tl.log(DebugLevel, message, args...)\r\n}\r\n\r\n// Info logs a message at InfoLevel\r\nfunc (l *Logger) Info(message string, args ...interface{}) {\r\n\tl.log(InfoLevel, message, args...)\r\n}\r\n\r\n// Warning logs a message at WarningLevel\r\nfunc (l *Logger) Warning(message string, args ...interface{}) {\r\n\tl.log(WarningLevel, message, args...)\r\n}\r\n\r\n// Error logs a message at ErrorLevel\r\nfunc (l *Logger) Error(message string, args ...interface{}) {\r\n\tl.log(ErrorLevel, message, args...)\r\n}\r\n\r\n// Close closes the log file\r\nfunc (l *Logger) Close() {\r\n\tif l.file != nil {\r\n\t\tl.file.Close()\r\n\t}\r\n}\r\n\r\n// UpdateProgress updates the progress on the console\r\nfunc (l *Logger) UpdateProgress(current, total int) {\r\n\tfmt.Printf(\"\\rProgress: %d/%d\", current, total)\r\n}\r\n\r\n// RotateLogs archives old log files\r\nfunc (l *Logger) RotateLogs() error {\r\n\t// Implementation of log rotation\r\n\t// This is a placeholder and should be implemented based on specific requirements\r\n\treturn nil\r\n}\r\n",
    "size": 3178,
    "modTime": "2024-10-20T16:31:08.8731335+02:00",
    "path": "internal\\logger\\logger.go"
  },
  {
    "name": "docx.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"archive/zip\"\r\n\t\"encoding/xml\"\r\n\t\"io/ioutil\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\nfunc init() {\r\n\tRegisterParser(\".docx\", NewDOCXParser)\r\n}\r\n\r\n// DOCXParser impl√©mente l'interface Parser pour les fichiers DOCX\r\ntype DOCXParser struct {\r\n\tmetadata map[string]string\r\n}\r\n\r\n// NewDOCXParser cr√©e une nouvelle instance de DOCXParser\r\nfunc NewDOCXParser() Parser {\r\n\treturn \u0026DOCXParser{\r\n\t\tmetadata: make(map[string]string),\r\n\t}\r\n}\r\n\r\n// Parse extrait le contenu textuel d'un fichier DOCX\r\nfunc (p *DOCXParser) Parse(path string) ([]byte, error) {\r\n\tlog.Debug(i18n.ParseStarted, \"DOCX\", path)\r\n\r\n\treader, err := zip.OpenReader(path)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ParseFailed, \"DOCX\", path, err)\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer reader.Close()\r\n\r\n\tvar textContent strings.Builder\r\n\tfor _, file := range reader.File {\r\n\t\tif file.Name == \"word/document.xml\" {\r\n\t\t\trc, err := file.Open()\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Error(i18n.ParseFailed, \"DOCX\", path, err)\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tdefer rc.Close()\r\n\r\n\t\t\tcontent, err := ioutil.ReadAll(rc)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Error(i18n.ParseFailed, \"DOCX\", path, err)\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\r\n\t\t\tvar document struct {\r\n\t\t\t\tBody struct {\r\n\t\t\t\t\tParagraphs []struct {\r\n\t\t\t\t\t\tRuns []struct {\r\n\t\t\t\t\t\t\tText string `xml:\"t\"`\r\n\t\t\t\t\t\t} `xml:\"r\"`\r\n\t\t\t\t\t} `xml:\"p\"`\r\n\t\t\t\t}\r\n\t\t\t}\r\n\r\n\t\t\terr = xml.Unmarshal(content, \u0026document)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Error(i18n.ParseFailed, \"DOCX\", path, err)\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\r\n\t\t\tfor _, paragraph := range document.Body.Paragraphs {\r\n\t\t\t\tfor _, run := range paragraph.Runs {\r\n\t\t\t\t\ttextContent.WriteString(run.Text)\r\n\t\t\t\t}\r\n\t\t\t\ttextContent.WriteString(\"\\n\")\r\n\t\t\t}\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\r\n\tp.extractMetadata(reader)\r\n\tlog.Info(i18n.ParseCompleted, \"DOCX\", path)\r\n\treturn []byte(textContent.String()), nil\r\n}\r\n\r\n// GetMetadata retourne les m√©tadonn√©es du fichier DOCX\r\nfunc (p *DOCXParser) GetMetadata() map[string]string {\r\n\treturn p.metadata\r\n}\r\n\r\n// extractMetadata extrait les m√©tadonn√©es du DOCX\r\nfunc (p *DOCXParser) extractMetadata(reader *zip.ReadCloser) {\r\n\tfor _, file := range reader.File {\r\n\t\tif file.Name == \"docProps/core.xml\" {\r\n\t\t\trc, err := file.Open()\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Warning(i18n.MetadataExtractionFailed, \"DOCX\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tdefer rc.Close()\r\n\r\n\t\t\tcontent, err := ioutil.ReadAll(rc)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Warning(i18n.MetadataExtractionFailed, \"DOCX\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\r\n\t\t\tvar coreProps struct {\r\n\t\t\t\tTitle          string `xml:\"title\"`\r\n\t\t\t\tSubject        string `xml:\"subject\"`\r\n\t\t\t\tCreator        string `xml:\"creator\"`\r\n\t\t\t\tKeywords       string `xml:\"keywords\"`\r\n\t\t\t\tDescription    string `xml:\"description\"`\r\n\t\t\t\tLastModifiedBy string `xml:\"lastModifiedBy\"`\r\n\t\t\t\tRevision       string `xml:\"revision\"`\r\n\t\t\t}\r\n\r\n\t\t\terr = xml.Unmarshal(content, \u0026coreProps)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Warning(i18n.MetadataExtractionFailed, \"DOCX\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\r\n\t\t\tp.metadata[\"title\"] = coreProps.Title\r\n\t\t\tp.metadata[\"subject\"] = coreProps.Subject\r\n\t\t\tp.metadata[\"creator\"] = coreProps.Creator\r\n\t\t\tp.metadata[\"keywords\"] = coreProps.Keywords\r\n\t\t\tp.metadata[\"description\"] = coreProps.Description\r\n\t\t\tp.metadata[\"lastModifiedBy\"] = coreProps.LastModifiedBy\r\n\t\t\tp.metadata[\"revision\"] = coreProps.Revision\r\n\t\t}\r\n\t}\r\n}\r\n",
    "size": 3334,
    "modTime": "2024-10-20T15:59:32.4569554+02:00",
    "path": "internal\\parser\\docx.go"
  },
  {
    "name": "html.go",
    "content": "package parser\r\n\r\nimport (\r\n    \"io/ioutil\"\r\n    \"strings\"\r\n\r\n    \"golang.org/x/net/html\"\r\n    \"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\nfunc init() {\r\n    RegisterParser(\".html\", NewHTMLParser)\r\n}\r\n\r\n// HTMLParser impl√©mente l'interface Parser pour les fichiers HTML\r\ntype HTMLParser struct {\r\n    metadata map[string]string\r\n}\r\n\r\n// NewHTMLParser cr√©e une nouvelle instance de HTMLParser\r\nfunc NewHTMLParser() Parser {\r\n    return \u0026HTMLParser{\r\n        metadata: make(map[string]string),\r\n    }\r\n}\r\n\r\n// Parse extrait le contenu textuel d'un fichier HTML\r\nfunc (p *HTMLParser) Parse(path string) ([]byte, error) {\r\n    log.Debug(i18n.ParseStarted, \"HTML\", path)\r\n    content, err := ioutil.ReadFile(path)\r\n    if err != nil {\r\n        log.Error(i18n.ParseFailed, \"HTML\", path, err)\r\n        return nil, err\r\n    }\r\n\r\n    doc, err := html.Parse(strings.NewReader(string(content)))\r\n    if err != nil {\r\n        log.Error(i18n.ParseFailed, \"HTML\", path, err)\r\n        return nil, err\r\n    }\r\n\r\n    var textContent strings.Builder\r\n    var extractText func(*html.Node)\r\n    extractText = func(n *html.Node) {\r\n        if n.Type == html.TextNode {\r\n            textContent.WriteString(n.Data)\r\n        }\r\n        for c := n.FirstChild; c != nil; c = c.NextSibling {\r\n            extractText(c)\r\n        }\r\n    }\r\n    extractText(doc)\r\n\r\n    p.extractMetadata(doc)\r\n    log.Info(i18n.ParseCompleted, \"HTML\", path)\r\n    return []byte(textContent.String()), nil\r\n}\r\n\r\n// GetMetadata retourne les m√©tadonn√©es du fichier HTML\r\nfunc (p *HTMLParser) GetMetadata() map[string]string {\r\n    return p.metadata\r\n}\r\n\r\n// extractMetadata extrait les m√©tadonn√©es du HTML\r\nfunc (p *HTMLParser) extractMetadata(doc *html.Node) {\r\n    var f func(*html.Node)\r\n    f = func(n *html.Node) {\r\n        if n.Type == html.ElementNode \u0026\u0026 n.Data == \"meta\" {\r\n            var name, content string\r\n            for _, a := range n.Attr {\r\n                if a.Key == \"name\" {\r\n                    name = a.Val\r\n                } else if a.Key == \"content\" {\r\n                    content = a.Val\r\n                }\r\n            }\r\n            if name != \"\" \u0026\u0026 content != \"\" {\r\n                p.metadata[name] = content\r\n            }\r\n        }\r\n        for c := n.FirstChild; c != nil; c = c.NextSibling {\r\n            f(c)\r\n        }\r\n    }\r\n    f(doc)\r\n}",
    "size": 2342,
    "modTime": "2024-10-20T16:03:50.0192112+02:00",
    "path": "internal\\parser\\html.go"
  },
  {
    "name": "logger.go",
    "content": "// internal/parser/logger.go\r\n\r\npackage parser\r\n\r\nimport (\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\nvar log = logger.GetLogger()\r\n",
    "size": 144,
    "modTime": "2024-10-20T15:59:02.1149669+02:00",
    "path": "internal\\parser\\logger.go"
  },
  {
    "name": "markdown.go",
    "content": "package parser\r\n\r\nimport (\r\n    \"io/ioutil\"\r\n    \"os\"\r\n    \"path/filepath\"\r\n\t\"fmt\"\r\n    \"time\"\r\n\r\n    \"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\nfunc init() {\r\n    RegisterParser(\".md\", NewMarkdownParser)\r\n}\r\n\r\n// MarkdownParser impl√©mente l'interface Parser pour les fichiers Markdown\r\ntype MarkdownParser struct {\r\n    metadata map[string]string\r\n}\r\n\r\n// NewMarkdownParser cr√©e une nouvelle instance de MarkdownParser\r\nfunc NewMarkdownParser() Parser {\r\n    return \u0026MarkdownParser{\r\n        metadata: make(map[string]string),\r\n    }\r\n}\r\n\r\n// Parse lit le contenu d'un fichier Markdown\r\nfunc (p *MarkdownParser) Parse(path string) ([]byte, error) {\r\n    log.Debug(i18n.ParseStarted, \"Markdown\", path)\r\n    content, err := ioutil.ReadFile(path)\r\n    if err != nil {\r\n        log.Error(i18n.ParseFailed, \"Markdown\", path, err)\r\n        return nil, err\r\n    }\r\n    p.extractMetadata(path)\r\n    log.Info(i18n.ParseCompleted, \"Markdown\", path)\r\n    return content, nil\r\n}\r\n\r\n// GetMetadata retourne les m√©tadonn√©es du fichier Markdown\r\nfunc (p *MarkdownParser) GetMetadata() map[string]string {\r\n    return p.metadata\r\n}\r\n\r\n// extractMetadata extrait les m√©tadonn√©es basiques du fichier\r\nfunc (p *MarkdownParser) extractMetadata(path string) {\r\n    info, err := os.Stat(path)\r\n    if err != nil {\r\n        log.Warning(i18n.MetadataExtractionFailed, path, err)\r\n        return\r\n    }\r\n    p.metadata[\"filename\"] = filepath.Base(path)\r\n    p.metadata[\"size\"] = fmt.Sprintf(\"%d\", info.Size())\r\n    p.metadata[\"modified\"] = info.ModTime().Format(time.RFC3339)\r\n}",
    "size": 1568,
    "modTime": "2024-10-20T16:03:58.3448335+02:00",
    "path": "internal\\parser\\markdown.go"
  },
  {
    "name": "parser.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n)\r\n\r\n// Parser d√©finit l'interface pour tous les analyseurs de documents\r\ntype Parser interface {\r\n\t// Parse prend le chemin d'un fichier et retourne son contenu en bytes\r\n\tParse(path string) ([]byte, error)\r\n\t// GetMetadata retourne les m√©tadonn√©es du document sous forme de map\r\n\tGetMetadata() map[string]string\r\n}\r\n\r\n// FormatParser est une fonction qui cr√©e un Parser sp√©cifique √† un format\r\ntype FormatParser func() Parser\r\n\r\n// formatParsers stocke les fonctions de cr√©ation de Parser pour chaque format support√©\r\nvar formatParsers = make(map[string]FormatParser)\r\n\r\n// RegisterParser enregistre un nouveau parser pour un format donn√©\r\nfunc RegisterParser(format string, parser FormatParser) {\r\n\tformatParsers[format] = parser\r\n}\r\n\r\n// GetParser retourne le parser appropri√© bas√© sur le format sp√©cifi√©\r\nfunc GetParser(format string) (Parser, error) {\r\n\tparserFunc, ok := formatParsers[format]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"unsupported format: %s\", format)\r\n\t}\r\n\treturn parserFunc(), nil\r\n}\r\n\r\n// ParseDirectory parcourt un r√©pertoire et parse tous les fichiers support√©s\r\nfunc ParseDirectory(path string, recursive bool) ([][]byte, error) {\r\n\tvar results [][]byte\r\n\terr := filepath.Walk(path, func(filePath string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif info.IsDir() {\r\n\t\t\tif !recursive \u0026\u0026 filePath != path {\r\n\t\t\t\treturn filepath.SkipDir\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\text := strings.ToLower(filepath.Ext(filePath))\r\n\t\tparser, err := GetParser(ext)\r\n\t\tif err != nil {\r\n\t\t\treturn nil // Skip unsupported files\r\n\t\t}\r\n\t\tcontent, err := parser.Parse(filePath)\r\n\t\tif err != nil {\r\n\t\t\tlog.Warning(\"Failed to parse file: %s, error: %v\", filePath, err)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tresults = append(results, content)\r\n\t\treturn nil\r\n\t})\r\n\treturn results, err\r\n}\r\n",
    "size": 1892,
    "modTime": "2024-10-20T16:02:54.2283253+02:00",
    "path": "internal\\parser\\parser.go"
  },
  {
    "name": "parser_test.go",
    "content": "package parser\r\n\r\nimport (\r\n    \"os\"\r\n    \"path/filepath\"\r\n    \"testing\"\r\n)\r\n\r\nfunc TestParsers(t *testing.T) {\r\n    testCases := []struct {\r\n        format string\r\n        content string\r\n    }{\r\n        {\".txt\", \"This is a test text file.\"},\r\n        {\".md\", \"# This is a Markdown file\\n\\nWith some content.\"},\r\n        {\".html\", \"\u003chtml\u003e\u003cbody\u003eThis is an HTML file\u003c/body\u003e\u003c/html\u003e\"},\r\n    }\r\n\r\n    for _, tc := range testCases {\r\n        t.Run(tc.format, func(t *testing.T) {\r\n            tempFile, err := createTempFile(tc.format, tc.content)\r\n            if err != nil {\r\n                t.Fatalf(\"Failed to create temp file: %v\", err)\r\n            }\r\n            defer os.Remove(tempFile)\r\n\r\n            parser, err := GetParser(tc.format)\r\n            if err != nil {\r\n                t.Fatalf(\"Failed to get parser: %v\", err)\r\n            }\r\n\r\n            content, err := parser.Parse(tempFile)\r\n            if err != nil {\r\n                t.Fatalf(\"Failed to parse file: %v\", err)\r\n            }\r\n\r\n            if string(content) != tc.content {\r\n                t.Errorf(\"Expected content %s, got %s\", tc.content, string(content))\r\n            }\r\n\r\n            metadata := parser.GetMetadata()\r\n            if len(metadata) == 0 {\r\n                t.Error(\"Expected non-empty metadata\")\r\n            }\r\n        })\r\n    }\r\n}\r\n\r\nfunc TestParseDirectory(t *testing.T) {\r\n    tempDir, err := os.MkdirTemp(\"\", \"parser_test\")\r\n    if err != nil {\r\n        t.Fatalf(\"Failed to create temp directory: %v\", err)\r\n    }\r\n    defer os.RemoveAll(tempDir)\r\n\r\n    files := []struct {\r\n        name string\r\n        content string\r\n    }{\r\n        {\"test1.txt\", \"Text file 1\"},\r\n        {\"test2.md\", \"# Markdown file\"},\r\n        {\"test3.html\", \"\u003chtml\u003e\u003cbody\u003eHTML file\u003c/body\u003e\u003c/html\u003e\"},\r\n    }\r\n\r\n    for _, f := range files {\r\n        err := os.WriteFile(filepath.Join(tempDir, f.name), []byte(f.content), 0644)\r\n        if err != nil {\r\n            t.Fatalf(\"Failed to create test file: %v\", err)\r\n        }\r\n    }\r\n\r\n    results, err := ParseDirectory(tempDir, false)\r\n    if err != nil {\r\n        t.Fatalf(\"ParseDirectory failed: %v\", err)\r\n    }\r\n\r\n    if len(results) != len(files) {\r\n        t.Errorf(\"Expected %d results, got %d\", len(files), len(results))\r\n    }\r\n}\r\n\r\nfunc createTempFile(ext, content string) (string, error) {\r\n    tmpfile, err := os.CreateTemp(\"\", \"test*\"+ext)\r\n    if err != nil {\r\n        return \"\", err\r\n    }\r\n    defer tmpfile.Close()\r\n\r\n    if _, err := tmpfile.Write([]byte(content)); err != nil {\r\n        return \"\", err\r\n    }\r\n\r\n    return tmpfile.Name(), nil\r\n}",
    "size": 2588,
    "modTime": "2024-10-20T12:32:19.3183805+02:00",
    "path": "internal\\parser\\parser_test.go"
  },
  {
    "name": "pdf.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"os\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/unidoc/unipdf/v3/core\"\r\n\t\"github.com/unidoc/unipdf/v3/extractor\"\r\n\t\"github.com/unidoc/unipdf/v3/model\"\r\n)\r\n\r\n// ParsePDF reads a PDF file and returns its content as a byte slice.\r\nfunc ParsePDF(path string) ([]byte, error) {\r\n\tlog.Debug(i18n.ParseStarted)\r\n\r\n\tf, err := os.Open(path)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ParseFailed, err)\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer f.Close()\r\n\r\n\tpdfReader, err := model.NewPdfReader(f)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ParseFailed, err)\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tnumPages, err := pdfReader.GetNumPages()\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ParseFailed, err)\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar content strings.Builder\r\n\tfor pageNum := 0; pageNum \u003c numPages; pageNum++ {\r\n\t\tpage, err := pdfReader.GetPage(pageNum + 1)\r\n\t\tif err != nil {\r\n\t\t\tlog.Error(i18n.PageParseFailed, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\tex, err := extractor.New(page)\r\n\t\tif err != nil {\r\n\t\t\tlog.Error(i18n.TextExtractionFailed, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\ttext, err := ex.ExtractText()\r\n\t\tif err != nil {\r\n\t\t\tlog.Error(i18n.TextExtractionFailed, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\r\n\t\tcontent.WriteString(text)\r\n\t}\r\n\r\n\tlog.Info(i18n.ParseCompleted)\r\n\treturn []byte(content.String()), nil\r\n}\r\n\r\n// GetPDFMetadata extracts metadata from a PDF file.\r\nfunc GetPDFMetadata(pdfReader *model.PdfReader) map[string]string {\r\n\tmetadata := make(map[string]string)\r\n\r\n\ttrailer, err := pdfReader.GetTrailer()\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.MetadataExtractionFailed, err)\r\n\t\treturn metadata\r\n\t}\r\n\r\n\tif trailer.Get(\"Info\") != nil {\r\n\t\tinfoDict, ok := trailer.Get(\"Info\").(*core.PdfObjectDictionary)\r\n\t\tif ok {\r\n\t\t\tfor _, key := range infoDict.Keys() {\r\n\t\t\t\tval := infoDict.Get(key)\r\n\t\t\t\tif strObj, isStr := val.(*core.PdfObjectString); isStr {\r\n\t\t\t\t\tmetadata[string(key)] = strObj.String()\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\treturn metadata\r\n}\r\n",
    "size": 1924,
    "modTime": "2024-10-20T16:09:12.7115872+02:00",
    "path": "internal\\parser\\pdf.go"
  },
  {
    "name": "text.go",
    "content": "package parser\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n)\r\n\r\nfunc init() {\r\n\tRegisterParser(\".txt\", NewTextParser)\r\n}\r\n\r\n// TextParser impl√©mente l'interface Parser pour les fichiers texte\r\ntype TextParser struct {\r\n\tmetadata map[string]string\r\n}\r\n\r\n// NewTextParser cr√©e une nouvelle instance de TextParser\r\nfunc NewTextParser() Parser {\r\n\treturn \u0026TextParser{\r\n\t\tmetadata: make(map[string]string),\r\n\t}\r\n}\r\n\r\n// Parse lit le contenu d'un fichier texte\r\nfunc (p *TextParser) Parse(path string) ([]byte, error) {\r\n\tlog.Debug(i18n.ParseStarted, \"text\", path)\r\n\tcontent, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ParseFailed, \"text\", path, err)\r\n\t\treturn nil, err\r\n\t}\r\n\tp.extractMetadata(path)\r\n\tlog.Info(i18n.ParseCompleted, \"text\", path)\r\n\treturn content, nil\r\n}\r\n\r\n// GetMetadata retourne les m√©tadonn√©es du fichier texte\r\nfunc (p *TextParser) GetMetadata() map[string]string {\r\n\treturn p.metadata\r\n}\r\n\r\n// extractMetadata extrait les m√©tadonn√©es basiques du fichier\r\nfunc (p *TextParser) extractMetadata(path string) {\r\n\tinfo, err := os.Stat(path)\r\n\tif err != nil {\r\n\t\tlog.Warning(i18n.MetadataExtractionFailed, path, err)\r\n\t\treturn\r\n\t}\r\n\tp.metadata[\"filename\"] = filepath.Base(path)\r\n\tp.metadata[\"size\"] = fmt.Sprintf(\"%d\", info.Size())\r\n\tp.metadata[\"modified\"] = info.ModTime().Format(time.RFC3339)\r\n}\r\n",
    "size": 1411,
    "modTime": "2024-10-20T16:00:04.3854661+02:00",
    "path": "internal\\parser\\text.go"
  },
  {
    "name": "pipeline.go",
    "content": "package pipeline\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n\t\"sync\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/converter\"\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/chrlesur/Ontology/internal/llm\"\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n\t\"github.com/chrlesur/Ontology/internal/parser\"\r\n\t\"github.com/chrlesur/Ontology/internal/segmenter\"\r\n)\r\n\r\n// Pipeline represents the main processing pipeline\r\ntype Pipeline struct {\r\n\tconfig *config.Config\r\n\tlogger *logger.Logger\r\n\tllm    llm.Client\r\n}\r\n\r\n// NewPipeline creates a new instance of the processing pipeline\r\nfunc NewPipeline() (*Pipeline, error) {\r\n\tcfg := config.GetConfig()\r\n\tlog := logger.GetLogger()\r\n\r\n\tclient, err := llm.GetClient(cfg.DefaultLLM, cfg.DefaultModel)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrInitLLMClient\"), err)\r\n\t}\r\n\r\n\treturn \u0026Pipeline{\r\n\t\tconfig: cfg,\r\n\t\tlogger: log,\r\n\t\tllm:    client,\r\n\t}, nil\r\n}\r\n\r\n// ExecutePipeline orchestrates the entire workflow\r\nfunc (p *Pipeline) ExecutePipeline(input string, passes int, existingOntology string) error {\r\n\tp.logger.Info(i18n.GetMessage(\"StartingPipeline\"))\r\n\r\n\tvar result string\r\n\tvar err error\r\n\r\n\tif existingOntology != \"\" {\r\n\t\tresult, err = p.loadExistingOntology(existingOntology)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrLoadExistingOntology\"), err)\r\n\t\t}\r\n\t}\r\n\r\n\tfor i := 0; i \u003c passes; i++ {\r\n\t\tp.logger.Info(i18n.GetMessage(\"StartingPass\"), i+1)\r\n\t\tresult, err = p.processSinglePass(input, result)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrProcessingPass\"), err)\r\n\t\t}\r\n\t}\r\n\r\n\terr = p.saveResult(result)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrSavingResult\"), err)\r\n\t}\r\n\r\n\tp.logger.Info(i18n.GetMessage(\"PipelineCompleted\"))\r\n\treturn nil\r\n}\r\n\r\nfunc (p *Pipeline) processSinglePass(input string, previousResult string) (string, error) {\r\n\tcontent, err := p.parseInput(input)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\r\n\tsegments, err := segmenter.Segment(content, segmenter.SegmentConfig{\r\n\t\tMaxTokens:   p.config.MaxTokens,\r\n\t\tContextSize: p.config.ContextSize,\r\n\t\tModel:       p.config.DefaultModel,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrSegmentContent\"), err)\r\n\t}\r\n\r\n\tresults := make([]string, len(segments))\r\n\tvar wg sync.WaitGroup\r\n\tfor i, segment := range segments {\r\n\t\twg.Add(1)\r\n\t\tgo func(i int, seg []byte) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tresult, err := p.processSegment(seg, previousResult)\r\n\t\t\tif err != nil {\r\n\t\t\t\tp.logger.Error(i18n.GetMessage(\"SegmentProcessingError\"), i, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tresults[i] = result\r\n\t\t}(i, segment)\r\n\t}\r\n\twg.Wait()\r\n\r\n\treturn p.combineResults(results)\r\n}\r\n\r\nfunc (p *Pipeline) parseInput(input string) ([]byte, error) {\r\n    info, err := os.Stat(input)\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrAccessInput\"), err)\r\n    }\r\n\r\n    if info.IsDir() {\r\n        return p.parseDirectory(input)\r\n    }\r\n\r\n    ext := filepath.Ext(input)\r\n    parser, err := parser.GetParser(ext)\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrUnsupportedFormat\"), err)\r\n    }\r\n\r\n    content, err := parser.Parse(input)\r\n    if err != nil {\r\n        return nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrParseFile\"), err)\r\n    }\r\n\r\n    return content, nil\r\n}\r\n\r\nfunc (p *Pipeline) parseDirectory(dir string) ([]byte, error) {\r\n\tvar content []byte\r\n\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !info.IsDir() {\r\n\t\t\text := filepath.Ext(path)\r\n\t\t\tparser, err := parser.GetParser(ext)\r\n\t\t\tif err != nil {\r\n\t\t\t\tp.logger.Warning(i18n.GetMessage(\"ErrUnsupportedFormat\"), path)\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tfileContent, err := parser.Parse(path)\r\n\t\t\tif err != nil {\r\n\t\t\t\tp.logger.Warning(i18n.GetMessage(\"ErrParseFile\"), path, err)\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tcontent = append(content, fileContent...)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrParseDirectory\"), err)\r\n\t}\r\n\treturn content, nil\r\n}\r\n\r\nfunc (p *Pipeline) processSegment(segment []byte, context string) (string, error) {\r\n\tresult, err := p.llm.Translate(string(segment), context)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrLLMTranslation\"), err)\r\n\t}\r\n\treturn result, nil\r\n}\r\n\r\nfunc (p *Pipeline) combineResults(results []string) (string, error) {\r\n\tcombined := strings.Join(results, \"\\n\")\r\n\treturn combined, nil\r\n}\r\n\r\nfunc (p *Pipeline) loadExistingOntology(path string) (string, error) {\r\n\tcontent, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrReadExistingOntology\"), err)\r\n\t}\r\n\treturn string(content), nil\r\n}\r\n\r\nfunc (p *Pipeline) saveResult(result string) error {\r\n\tqsc := converter.NewQuickStatementConverter(p.logger)\r\n\r\n\tqs, err := qsc.Convert([]byte(result), \"\", \"\") // Nous utilisons des cha√Ænes vides pour context et ontology pour l'instant\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrConvertQuickStatement\"), err)\r\n\t}\r\n\r\n\tfilename := fmt.Sprintf(\"%s.tsv\", p.config.OntologyName)\r\n\terr = ioutil.WriteFile(filename, []byte(qs), 0644)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrWriteOutput\"), err)\r\n\t}\r\n\r\n\tif p.config.ExportRDF {\r\n\t\trdf, err := qsc.ConvertToRDF(qs)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrConvertRDF\"), err)\r\n\t\t}\r\n\t\terr = ioutil.WriteFile(fmt.Sprintf(\"%s.rdf\", p.config.OntologyName), []byte(rdf), 0644)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrWriteRDF\"), err)\r\n\t\t}\r\n\t}\r\n\r\n\tif p.config.ExportOWL {\r\n\t\towl, err := qsc.ConvertToOWL(qs)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrConvertOWL\"), err)\r\n\t\t}\r\n\t\terr = ioutil.WriteFile(fmt.Sprintf(\"%s.owl\", p.config.OntologyName), []byte(owl), 0644)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"%s: %w\", i18n.GetMessage(\"ErrWriteOWL\"), err)\r\n\t\t}\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n",
    "size": 6133,
    "modTime": "2024-10-20T16:58:04.4595558+02:00",
    "path": "internal\\pipeline\\pipeline.go"
  },
  {
    "name": "segmenter.go",
    "content": "package segmenter\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"io\"\r\n\t\"strings\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/i18n\"\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n\t\"github.com/pkoukk/tiktoken-go\"\r\n)\r\n\r\nvar (\r\n\tErrInvalidContent = errors.New(i18n.ErrInvalidContent)\r\n\tErrTokenization   = errors.New(i18n.ErrTokenization)\r\n)\r\n\r\nvar log = logger.GetLogger()\r\n\r\n// SegmentConfig holds the configuration for segmentation\r\ntype SegmentConfig struct {\r\n\tMaxTokens   int\r\n\tContextSize int\r\n\tModel       string\r\n}\r\n\r\n// Segment divides the content into segments of maxTokens\r\nfunc Segment(content []byte, cfg SegmentConfig) ([][]byte, error) {\r\n\tlog.Debug(i18n.LogSegmentationStarted)\r\n\tif len(content) == 0 {\r\n\t\treturn nil, ErrInvalidContent\r\n\t}\r\n\r\n\ttokenizer, err := getTokenizer(cfg.Model)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\r\n\tvar segments [][]byte\r\n\treader := bytes.NewReader(content)\r\n\tbuffer := new(bytes.Buffer)\r\n\ttokenCount := 0\r\n\r\n\tfor {\r\n\t\tchar, _, err := reader.ReadRune()\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.ErrReadingContent, err)\r\n\t\t}\r\n\r\n\t\tbuffer.WriteRune(char)\r\n\t\ttokenCount = CountTokens(buffer.Bytes(), tokenizer)\r\n\r\n\t\tif tokenCount \u003e= cfg.MaxTokens || char == '.' || char == '!' || char == '?' {\r\n\t\t\tsegment := make([]byte, buffer.Len())\r\n\t\t\tcopy(segment, buffer.Bytes())\r\n\t\t\tsegments = append(segments, segment)\r\n\t\t\tbuffer.Reset()\r\n\t\t\ttokenCount = 0\r\n\t\t}\r\n\t}\r\n\r\n\tif buffer.Len() \u003e 0 {\r\n\t\tsegments = append(segments, buffer.Bytes())\r\n\t}\r\n\r\n\tlog.Info(i18n.LogSegmentationCompleted, len(segments))\r\n\treturn segments, nil\r\n}\r\n\r\n// GetContext returns the context of previous segments\r\nfunc GetContext(segments [][]byte, currentIndex int, cfg SegmentConfig) string {\r\n\tlog.Debug(i18n.LogContextGeneration)\r\n\tif currentIndex == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\r\n\ttokenizer, err := getTokenizer(cfg.Model)\r\n\tif err != nil {\r\n\t\tlog.Error(i18n.ErrTokenizerInitialization, err)\r\n\t\treturn \"\"\r\n\t}\r\n\r\n\tvar context strings.Builder\r\n\ttokenCount := 0\r\n\r\n\tfor i := currentIndex - 1; i \u003e= 0; i-- {\r\n\t\tsegment := segments[i]\r\n\t\tsegmentTokens := CountTokens(segment, tokenizer)\r\n\r\n\t\tif tokenCount+segmentTokens \u003e cfg.ContextSize {\r\n\t\t\tbreak\r\n\t\t}\r\n\r\n\t\tcontext.Write(segment)\r\n\t\tcontext.WriteString(\" \")\r\n\t\ttokenCount += segmentTokens\r\n\t}\r\n\r\n\treturn strings.TrimSpace(context.String())\r\n}\r\n\r\n// CountTokens returns the number of tokens in the content\r\nfunc CountTokens(content []byte, tokenizer *tiktoken.Tiktoken) int {\r\n\ttokens := tokenizer.Encode(string(content), nil, nil)\r\n\treturn len(tokens)\r\n}\r\n\r\n// MergeSegments reconstitutes the original document from segments\r\nfunc MergeSegments(segments [][]byte) []byte {\r\n\tlog.Debug(i18n.LogMergingSegments)\r\n\treturn bytes.Join(segments, []byte(\" \"))\r\n}\r\n\r\n// getTokenizer returns a tokenizer for the specified model\r\nfunc getTokenizer(model string) (*tiktoken.Tiktoken, error) {\r\n\tencoding, err := tiktoken.GetEncoding(\"cl100k_base\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %w\", i18n.ErrTokenizerInitialization, err)\r\n\t}\r\n\treturn encoding, nil\r\n}\r\n\r\n// CalibrateTokenCount adjusts the token count based on the LLM model\r\nfunc CalibrateTokenCount(count int, model string) int {\r\n\t// Implement model-specific calibration logic here\r\n\t// For now, we'll just return the original count\r\n\treturn count\r\n}\r\n",
    "size": 3320,
    "modTime": "2024-10-20T16:15:50.4780138+02:00",
    "path": "internal\\segmenter\\segmenter.go"
  },
  {
    "name": "tokenizer.go",
    "content": "package tokenizer\r\n\r\nimport (\r\n\t\"github.com/pkoukk/tiktoken-go\"\r\n)\r\n\r\n// CountTokens returns the number of tokens in the given text\r\nfunc CountTokens(text string) (int, error) {\r\n\tencoding, err := tiktoken.GetEncoding(\"cl100k_base\")\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\ttokens := encoding.Encode(text, nil, nil)\r\n\treturn len(tokens), nil\r\n}\r\n",
    "size": 346,
    "modTime": "2024-10-20T15:16:21.4160242+02:00",
    "path": "internal\\tokenizer\\tokenizer.go"
  }
]