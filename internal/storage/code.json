[
  {
    "name": "detector.go",
    "content": "// internal/storage/detector.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n)\r\n\r\n// DetectStorageType détermine le type de stockage basé sur le chemin d'entrée\r\nfunc DetectStorageType(path string) string {\r\n\tlog.Debug(\"Detecting storage type for path: %s\", path)\r\n\r\n\t// Normaliser le chemin pour gérer les chemins Windows\r\n\tnormalizedPath := filepath.ToSlash(path)\r\n\r\n\tif strings.HasPrefix(strings.ToLower(normalizedPath), \"s3://\") {\r\n\t\tlog.Debug(\"Detected S3 storage type\")\r\n\t\treturn S3StorageType\r\n\t}\r\n\tlog.Debug(\"Detected Local storage type\")\r\n\treturn LocalStorageType\r\n}\r\n",
    "size": 598,
    "modTime": "2024-11-04T19:38:48.2068634+01:00",
    "path": "detector.go"
  },
  {
    "name": "errors.go",
    "content": "// internal/storage/errors.go\r\n\r\npackage storage\r\n\r\nimport \"errors\"\r\n\r\nvar (\r\n    // ErrInvalidS3URI est renvoyée lorsqu'une URI S3 est invalide\r\n    ErrInvalidS3URI = errors.New(\"invalid S3 URI format\")\r\n)",
    "size": 207,
    "modTime": "2024-11-04T14:09:24.9274288+01:00",
    "path": "errors.go"
  },
  {
    "name": "factory.go",
    "content": "// internal/storage/factory.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"fmt\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/config\"\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\n// NewStorage crée et retourne une instance de Storage basée sur la configuration\r\nfunc NewStorage(cfg *config.Config, inputPath string) (Storage, error) {\r\n\tlog := logger.GetLogger()\r\n\r\n\tstorageType := DetectStorageType(inputPath)\r\n\tlog.Debug(\"Creating new storage with type: %s\", storageType)\r\n\r\n\tswitch storageType {\r\n\tcase LocalStorageType:\r\n\t\tlog.Debug(\"Creating Local storage\")\r\n\t\treturn NewLocalStorage(cfg.Storage.LocalPath, logger.GetLogger()), nil\r\n\tcase S3StorageType:\r\n\t\tlog.Debug(\"Creating S3 storage\")\r\n\t\treturn NewS3Storage(\r\n\t\t\tcfg.Storage.S3.Region,\r\n\t\t\tcfg.Storage.S3.Endpoint,\r\n\t\t\tcfg.Storage.S3.AccessKeyID,\r\n\t\t\tcfg.Storage.S3.SecretAccessKey,\r\n\t\t\tlog,\r\n\t\t)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported storage type: %s\", storageType)\r\n\t}\r\n}\r\n",
    "size": 946,
    "modTime": "2024-11-05T18:50:34.7186176+01:00",
    "path": "factory.go"
  },
  {
    "name": "local.go",
    "content": "// internal/storage/local.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"io\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"time\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\ntype LocalStorage struct {\r\n\tbasePath string\r\n\tlogger   *logger.Logger\r\n}\r\n\r\ntype localFileInfo struct {\r\n\tos.FileInfo\r\n}\r\n\r\nfunc NewLocalStorage(basePath string, logger *logger.Logger) *LocalStorage {\r\n\treturn \u0026LocalStorage{\r\n\t\tbasePath: basePath,\r\n\t\tlogger:   logger,\r\n\t}\r\n}\r\n\r\nfunc (ls *LocalStorage) Read(path string) ([]byte, error) {\r\n\tls.logger.Debug(\"Reading from local storage: %s\", path)\r\n\tfullPath := ls.getFullPath(path)\r\n\tls.logger.Debug(\"Full path for reading: %s\", fullPath)\r\n\r\n\tfileInfo, err := os.Stat(fullPath)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get file info: %w\", err)\r\n\t}\r\n\r\n\tif fileInfo.IsDir() {\r\n\t\treturn ls.readDirectory(fullPath)\r\n\t}\r\n\r\n\treturn ioutil.ReadFile(fullPath)\r\n}\r\n\r\nfunc (ls *LocalStorage) readDirectory(dirPath string) ([]byte, error) {\r\n\tvar content []byte\r\n\terr := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !info.IsDir() {\r\n\t\t\tfileContent, err := ioutil.ReadFile(path)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcontent = append(content, fileContent...)\r\n\t\t\tcontent = append(content, '\\n') // Add newline between files\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to read directory: %w\", err)\r\n\t}\r\n\treturn content, nil\r\n}\r\n\r\nfunc (ls *LocalStorage) Write(path string, data []byte) error {\r\n\tls.logger.Debug(\"Writing file: %s\", path)\r\n\tfullPath := ls.getFullPath(path)\r\n\tls.logger.Debug(\"Full path for writing: %s\", fullPath)\r\n\r\n\t// Assurez-vous que le répertoire existe\r\n\tdir := filepath.Dir(fullPath)\r\n\tif err := os.MkdirAll(dir, 0755); err != nil {\r\n\t\treturn err\r\n\t}\r\n\r\n\treturn ioutil.WriteFile(fullPath, data, 0644)\r\n}\r\n\r\n// getFullPath gère la conversion des chemins relatifs en chemins absolus\r\nfunc (ls *LocalStorage) getFullPath(path string) string {\r\n\tif filepath.IsAbs(path) {\r\n\t\treturn filepath.Clean(path)\r\n\t}\r\n\treturn filepath.Clean(filepath.Join(ls.basePath, path))\r\n}\r\n\r\nfunc (ls *LocalStorage) List(prefix string) ([]string, error) {\r\n\tls.logger.Debug(\"Listing files with prefix: %s\", prefix)\r\n\r\n\tfullPath := ls.getFullPath(prefix)\r\n\tls.logger.Debug(\"Full path for listing: %s\", fullPath)\r\n\r\n\tvar files []string\r\n\terr := filepath.Walk(fullPath, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !info.IsDir() {\r\n\t\t\t// Retourner le chemin complet au lieu du chemin relatif\r\n\t\t\tfiles = append(files, path)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to list directory contents: %w\", err)\r\n\t}\r\n\r\n\tls.logger.Debug(\"Listed %d files\", len(files))\r\n\treturn files, nil\r\n}\r\n\r\nfunc (ls *LocalStorage) Delete(path string) error {\r\n\tls.logger.Debug(\"Deleting file: %s\", path)\r\n\tfullPath := filepath.Join(ls.basePath, path)\r\n\treturn os.Remove(fullPath)\r\n}\r\n\r\nfunc (ls *LocalStorage) Exists(path string) (bool, error) {\r\n\tls.logger.Debug(\"Checking if file exists: %s\", path)\r\n\tfullPath := filepath.Join(ls.basePath, path)\r\n\t_, err := os.Stat(fullPath)\r\n\tif err == nil {\r\n\t\treturn true, nil\r\n\t}\r\n\tif os.IsNotExist(err) {\r\n\t\treturn false, nil\r\n\t}\r\n\treturn false, err\r\n}\r\n\r\nfunc (ls *LocalStorage) IsDirectory(path string) (bool, error) {\r\n\tls.logger.Debug(\"Checking if path is a directory: %s\", path)\r\n\r\n\t// Utiliser le chemin tel quel s'il est absolu, sinon le joindre au chemin de base\r\n\tfullPath := path\r\n\tif !filepath.IsAbs(path) {\r\n\t\tfullPath = filepath.Join(ls.basePath, path)\r\n\t}\r\n\r\n\tls.logger.Debug(\"Full path for directory check: %s\", fullPath)\r\n\r\n\tfileInfo, err := os.Stat(fullPath)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\tls.logger.Debug(\"Path does not exist: %s\", fullPath)\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\tls.logger.Error(\"Error checking directory: %v\", err)\r\n\t\treturn false, err\r\n\t}\r\n\r\n\tisDir := fileInfo.IsDir()\r\n\tls.logger.Debug(\"Is directory: %v\", isDir)\r\n\treturn isDir, nil\r\n}\r\n\r\nfunc (ls *LocalStorage) GetReader(path string) (io.ReadCloser, error) {\r\n\tls.logger.Debug(\"Getting reader for local file: %s\", path)\r\n\tfullPath := ls.getFullPath(path)\r\n\treturn os.Open(fullPath)\r\n}\r\n\r\nfunc (ls *LocalStorage) Stat(path string) (FileInfo, error) {\r\n\tls.logger.Debug(\"Getting file info: %s\", path)\r\n\tfullPath := ls.getFullPath(path)\r\n\tinfo, err := os.Stat(fullPath)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get file info: %w\", err)\r\n\t}\r\n\treturn \u0026localFileInfo{info}, nil\r\n}\r\n\r\n// Assurez-vous que localFileInfo implémente toutes les méthodes de FileInfo\r\nfunc (lfi *localFileInfo) Name() string       { return lfi.FileInfo.Name() }\r\nfunc (lfi *localFileInfo) Size() int64        { return lfi.FileInfo.Size() }\r\nfunc (lfi *localFileInfo) Mode() os.FileMode  { return lfi.FileInfo.Mode() }\r\nfunc (lfi *localFileInfo) ModTime() time.Time { return lfi.FileInfo.ModTime() }\r\nfunc (lfi *localFileInfo) IsDir() bool        { return lfi.FileInfo.IsDir() }\r\nfunc (lfi *localFileInfo) Sys() interface{}   { return lfi.FileInfo.Sys() }\r\n",
    "size": 5100,
    "modTime": "2024-11-05T23:17:30.9132253+01:00",
    "path": "local.go"
  },
  {
    "name": "s3.go",
    "content": "// internal/storage/s3.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"io\"\r\n\t\"io/ioutil\"\r\n\t\"os\"\r\n\t\"path/filepath\"\r\n\t\"strings\"\r\n\t\"time\"\r\n\r\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\r\n\t\"github.com/aws/aws-sdk-go-v2/config\"\r\n\t\"github.com/aws/aws-sdk-go-v2/credentials\"\r\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\r\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\r\n\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n)\r\n\r\ntype S3ClientInterface interface {\r\n\tGetObject(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error)\r\n\tPutObject(ctx context.Context, params *s3.PutObjectInput, optFns ...func(*s3.Options)) (*s3.PutObjectOutput, error)\r\n\tListObjectsV2(ctx context.Context, params *s3.ListObjectsV2Input, optFns ...func(*s3.Options)) (*s3.ListObjectsV2Output, error)\r\n\tDeleteObject(ctx context.Context, params *s3.DeleteObjectInput, optFns ...func(*s3.Options)) (*s3.DeleteObjectOutput, error)\r\n\tHeadObject(ctx context.Context, params *s3.HeadObjectInput, optFns ...func(*s3.Options)) (*s3.HeadObjectOutput, error)\r\n}\r\n\r\ntype S3Storage struct {\r\n\tclient S3ClientInterface\r\n\tbucket string\r\n\tlogger Logger\r\n}\r\n\r\ntype s3FileInfo struct {\r\n\tname    string\r\n\tsize    int64\r\n\tmodTime time.Time\r\n}\r\n\r\nfunc (fi *s3FileInfo) Name() string       { return fi.name }\r\nfunc (fi *s3FileInfo) Size() int64        { return fi.size }\r\nfunc (fi *s3FileInfo) Mode() os.FileMode  { return 0 }\r\nfunc (fi *s3FileInfo) ModTime() time.Time { return fi.modTime }\r\nfunc (fi *s3FileInfo) IsDir() bool        { return false }\r\nfunc (fi *s3FileInfo) Sys() interface{}   { return nil }\r\n\r\nfunc NewS3Storage(region, endpoint, accessKeyID, secretAccessKey string, logger *logger.Logger) (*S3Storage, error) {\r\n\tlogger.Debug(\"Initializing S3 storage with region: %s, endpoint: %s\", region, endpoint)\r\n\r\n\tcfg, err := config.LoadDefaultConfig(context.TODO(),\r\n\t\tconfig.WithRegion(region),\r\n\t\tconfig.WithEndpointResolver(aws.EndpointResolverFunc(\r\n\t\t\tfunc(service, region string) (aws.Endpoint, error) {\r\n\t\t\t\treturn aws.Endpoint{URL: endpoint}, nil\r\n\t\t\t})),\r\n\t\tconfig.WithCredentialsProvider(credentials.NewStaticCredentialsProvider(accessKeyID, secretAccessKey, \"\")),\r\n\t)\r\n\tif err != nil {\r\n\t\tlogger.Error(\"Failed to load S3 config: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to load S3 config: %w\", err)\r\n\t}\r\n\r\n\tclient := s3.NewFromConfig(cfg, func(o *s3.Options) {\r\n\t\to.UsePathStyle = true\r\n\t})\r\n\r\n\treturn \u0026S3Storage{\r\n\t\tclient: client,\r\n\t\tlogger: logger,\r\n\t}, nil\r\n}\r\n\r\nfunc (s *S3Storage) Read(path string) ([]byte, error) {\r\n\ts.logger.Debug(\"Reading from S3: %s\", path)\r\n\tbucket, key, err := ParseS3URI(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to parse S3 URI: %w\", err)\r\n\t}\r\n\r\n\ts.logger.Debug(\"Parsed S3 path - Bucket: %s, Key: %s\", bucket, key)\r\n\r\n\tresult, err := s.client.GetObject(context.TODO(), \u0026s3.GetObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to read file from S3: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to read file from S3: %w\", err)\r\n\t}\r\n\tdefer result.Body.Close()\r\n\r\n\tcontent, err := ioutil.ReadAll(result.Body)\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to read content from S3 object: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to read content from S3 object: %w\", err)\r\n\t}\r\n\r\n\ts.logger.Debug(\"Successfully read %d bytes from S3\", len(content))\r\n\treturn content, nil\r\n}\r\n\r\nfunc (s *S3Storage) Write(path string, data []byte) error {\r\n\ts.logger.Debug(\"Writing file to S3: %s\", path)\r\n\r\n\tbucket, key, err := ParseS3URI(path)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to parse S3 URI: %w\", err)\r\n\t}\r\n\r\n\t_, err = s.client.PutObject(context.TODO(), \u0026s3.PutObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t\tBody:   bytes.NewReader(data),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to write file to S3: %v\", err)\r\n\t\treturn fmt.Errorf(\"failed to write file to S3: %w\", err)\r\n\t}\r\n\r\n\ts.logger.Debug(\"Successfully wrote %d bytes to S3\", len(data))\r\n\treturn nil\r\n}\r\n\r\nfunc (s *S3Storage) List(prefix string) ([]string, error) {\r\n\ts.logger.Debug(\"Listing files in S3 with prefix: %s\", prefix)\r\n\r\n\tbucket, key, err := ParseS3URI(prefix)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to parse S3 URI: %w\", err)\r\n\t}\r\n\r\n\tvar files []string\r\n\tpaginator := s3.NewListObjectsV2Paginator(s.client, \u0026s3.ListObjectsV2Input{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tPrefix: aws.String(key),\r\n\t})\r\n\r\n\t// Extrayez le domaine de l'URL originale\r\n\tdomainParts := strings.SplitN(prefix, \"/\", 4)\r\n\tdomain := strings.Join(domainParts[:3], \"/\")\r\n\r\n\tfor paginator.HasMorePages() {\r\n\t\tpage, err := paginator.NextPage(context.TODO())\r\n\t\tif err != nil {\r\n\t\t\ts.logger.Error(\"Failed to list files in S3: %v\", err)\r\n\t\t\treturn nil, fmt.Errorf(\"failed to list files in S3: %w\", err)\r\n\t\t}\r\n\t\tfor _, obj := range page.Contents {\r\n\t\t\tif !strings.HasSuffix(*obj.Key, \"/\") { // Ignore directory markers\r\n\t\t\t\tfiles = append(files, fmt.Sprintf(\"%s/%s/%s\", domain, bucket, *obj.Key))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\treturn files, nil\r\n}\r\n\r\nfunc (s *S3Storage) Delete(path string) error {\r\n\ts.logger.Debug(\"Deleting file from S3: %s\", path)\r\n\r\n\t_, err := s.client.DeleteObject(context.TODO(), \u0026s3.DeleteObjectInput{\r\n\t\tBucket: aws.String(s.bucket),\r\n\t\tKey:    aws.String(path),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to delete file from S3: %v\", err)\r\n\t\treturn fmt.Errorf(\"failed to delete file from S3: %w\", err)\r\n\t}\r\n\r\n\treturn nil\r\n}\r\n\r\nfunc (s *S3Storage) Exists(path string) (bool, error) {\r\n\ts.logger.Debug(\"Checking if file exists in S3: %s\", path)\r\n\r\n\t_, err := s.client.HeadObject(context.TODO(), \u0026s3.HeadObjectInput{\r\n\t\tBucket: aws.String(s.bucket),\r\n\t\tKey:    aws.String(path),\r\n\t})\r\n\tif err != nil {\r\n\t\tvar nsk *types.NoSuchKey\r\n\t\tif errors.As(err, \u0026nsk) || strings.Contains(err.Error(), \"NotFound\") || strings.Contains(err.Error(), \"404\") {\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\ts.logger.Error(\"Error checking if file exists in S3: %v\", err)\r\n\t\treturn false, fmt.Errorf(\"error checking if file exists in S3: %w\", err)\r\n\t}\r\n\r\n\treturn true, nil\r\n}\r\n\r\nfunc (s *S3Storage) IsDirectory(path string) (bool, error) {\r\n\ts.logger.Debug(\"Checking if path is a directory in S3: %s\", path)\r\n\r\n\tbucket, key, err := ParseS3URI(path)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to parse S3 URI: %w\", err)\r\n\t}\r\n\ts.logger.Error(\"Parsed S3 URI: %s %s\", bucket, key)\r\n\r\n\t// Assurez-vous que la clé se termine par '/'\r\n\tif !strings.HasSuffix(key, \"/\") {\r\n\t\tkey += \"/\"\r\n\t}\r\n\r\n\ts.logger.Debug(\"Checking key %s on bucket %s for path %s\", key, bucket, path)\r\n\r\n\tresult, err := s.client.ListObjectsV2(context.TODO(), \u0026s3.ListObjectsV2Input{\r\n\t\tBucket:    aws.String(bucket),\r\n\t\tPrefix:    aws.String(key),\r\n\t\tDelimiter: aws.String(\"/\"),\r\n\t\tMaxKeys:   aws.Int32(1),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Error checking if path is a directory in S3: %v\", err)\r\n\t\treturn false, fmt.Errorf(\"error checking if path is a directory in S3: %w\", err)\r\n\t}\r\n\r\n\treturn len(result.CommonPrefixes) \u003e 0 || len(result.Contents) \u003e 0, nil\r\n}\r\n\r\nfunc (s *S3Storage) Stat(path string) (FileInfo, error) {\r\n\ts.logger.Debug(\"Getting file info from S3: %s\", path)\r\n\r\n\tresult, err := s.client.HeadObject(context.TODO(), \u0026s3.HeadObjectInput{\r\n\t\tBucket: aws.String(s.bucket),\r\n\t\tKey:    aws.String(path),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to get file info from S3: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to get file info from S3: %w\", err)\r\n\t}\r\n\r\n\tsize := result.ContentLength\r\n\tif size == nil {\r\n\t\tsize = aws.Int64(0)\r\n\t}\r\n\treturn \u0026s3FileInfo{\r\n\t\tname:    filepath.Base(path),\r\n\t\tsize:    *size,\r\n\t\tmodTime: *result.LastModified,\r\n\t}, nil\r\n}\r\n\r\nfunc (s *S3Storage) ReadFromBucket(bucket, key string) ([]byte, error) {\r\n\ts.logger.Debug(\"Reading file from S3: bucket=%s, key=%s\", bucket, key)\r\n\r\n\tresult, err := s.client.GetObject(context.TODO(), \u0026s3.GetObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to read file from S3: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to read file from S3: %w\", err)\r\n\t}\r\n\tdefer result.Body.Close()\r\n\r\n\treturn ioutil.ReadAll(result.Body)\r\n}\r\n\r\nfunc (s *S3Storage) StatObject(bucket, key string) (os.FileInfo, error) {\r\n\ts.logger.Debug(\"Getting file info from S3 - Bucket: %s, Key: %s\", bucket, key)\r\n\r\n\tresult, err := s.client.HeadObject(context.TODO(), \u0026s3.HeadObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t})\r\n\tif err != nil {\r\n\t\ts.logger.Error(\"Failed to get file info from S3: %v\", err)\r\n\t\treturn nil, fmt.Errorf(\"failed to get file info from S3: %w\", err)\r\n\t}\r\n\r\n\treturn \u0026s3FileInfo{\r\n\t\tname:    filepath.Base(key),\r\n\t\tsize:    *result.ContentLength,\r\n\t\tmodTime: *result.LastModified,\r\n\t}, nil\r\n}\r\n\r\nfunc ParseS3URI(uri string) (bucket, key string, err error) {\r\n\tif !strings.HasPrefix(strings.ToLower(uri), \"s3://\") {\r\n\t\treturn \"\", \"\", fmt.Errorf(\"invalid S3 URI format on prefix\")\r\n\t}\r\n\r\n\t// Remove the \"s3://\" prefix\r\n\turi = strings.TrimPrefix(uri, \"s3://\")\r\n\r\n\t// Split the remaining string into parts\r\n\tparts := strings.SplitN(uri, \"/\", 3)\r\n\r\n\tif len(parts) \u003c 3 {\r\n\t\treturn \"\", \"\", fmt.Errorf(\"invalid S3 URI format on len(part) : %s\", uri)\r\n\t}\r\n\r\n\t// The first part is the domain\r\n\t// The second part is the bucket\r\n\tbucket = parts[1]\r\n\t// The key is everything after the bucket\r\n\tkey = parts[2]\r\n\r\n\treturn bucket, key, nil\r\n}\r\n\r\nfunc (s *S3Storage) readS3Directory(bucket, prefix string) ([]byte, error) {\r\n\ts.logger.Debug(\"Reading S3 directory: bucket=%s, prefix=%s\", bucket, prefix)\r\n\tvar content []byte\r\n\tpaginator := s3.NewListObjectsV2Paginator(s.client, \u0026s3.ListObjectsV2Input{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tPrefix: aws.String(prefix),\r\n\t})\r\n\r\n\tfor paginator.HasMorePages() {\r\n\t\tpage, err := paginator.NextPage(context.TODO())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to list S3 objects: %w\", err)\r\n\t\t}\r\n\r\n\t\tfor _, obj := range page.Contents {\r\n\t\t\tif !strings.HasSuffix(*obj.Key, \"/\") { // Skip directory markers\r\n\t\t\t\tobjContent, err := s.getS3ObjectContent(bucket, *obj.Key)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tcontent = append(content, objContent...)\r\n\t\t\t\tcontent = append(content, '\\n') // Add newline between files\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\r\n\tif len(content) == 0 {\r\n\t\treturn nil, fmt.Errorf(\"no content found in S3 directory: %s/%s\", bucket, prefix)\r\n\t}\r\n\r\n\ts.logger.Debug(\"Successfully read %d bytes from S3 directory\", len(content))\r\n\treturn content, nil\r\n}\r\n\r\nfunc (s *S3Storage) getS3ObjectContent(bucket, key string) ([]byte, error) {\r\n\tresult, err := s.client.GetObject(context.TODO(), \u0026s3.GetObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get S3 object: %w\", err)\r\n\t}\r\n\tdefer result.Body.Close()\r\n\r\n\treturn ioutil.ReadAll(result.Body)\r\n}\r\n\r\nfunc (s *S3Storage) GetReader(path string) (io.ReadCloser, error) {\r\n\ts.logger.Debug(\"Getting reader for S3 object: %s\", path)\r\n\tbucket, key, err := ParseS3URI(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to parse S3 URI: %w\", err)\r\n\t}\r\n\r\n\tresult, err := s.client.GetObject(context.TODO(), \u0026s3.GetObjectInput{\r\n\t\tBucket: aws.String(bucket),\r\n\t\tKey:    aws.String(key),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get S3 object: %w\", err)\r\n\t}\r\n\r\n\treturn result.Body, nil\r\n}\r\n",
    "size": 11350,
    "modTime": "2024-11-05T19:20:57.630719+01:00",
    "path": "s3.go"
  },
  {
    "name": "s3_test.go",
    "content": "// internal/storage/s3_test.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"bytes\"\r\n\t\"context\"\r\n\t\"io/ioutil\"\r\n\t\"testing\"\r\n\t\"time\"\r\n\r\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\r\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\r\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\r\n\t\"github.com/stretchr/testify/assert\"\r\n\t\"github.com/stretchr/testify/mock\"\r\n)\r\n\r\n// MockLogger est un mock de l'interface Logger\r\ntype MockLogger struct {\r\n\tmock.Mock\r\n}\r\n\r\nfunc (m *MockLogger) Debug(format string, args ...interface{}) {\r\n\tm.Called(format, args)\r\n}\r\n\r\nfunc (m *MockLogger) Info(format string, args ...interface{}) {\r\n\tm.Called(format, args)\r\n}\r\n\r\nfunc (m *MockLogger) Warning(format string, args ...interface{}) {\r\n\tm.Called(format, args)\r\n}\r\n\r\nfunc (m *MockLogger) Error(format string, args ...interface{}) {\r\n\tm.Called(format, args)\r\n}\r\n\r\n// MockS3Client est un mock du client S3\r\ntype MockS3Client struct {\r\n\tmock.Mock\r\n}\r\n\r\nfunc (m *MockS3Client) GetObject(ctx context.Context, params *s3.GetObjectInput, optFns ...func(*s3.Options)) (*s3.GetObjectOutput, error) {\r\n\targs := m.Called(ctx, params, optFns)\r\n\treturn args.Get(0).(*s3.GetObjectOutput), args.Error(1)\r\n}\r\n\r\nfunc (m *MockS3Client) PutObject(ctx context.Context, params *s3.PutObjectInput, optFns ...func(*s3.Options)) (*s3.PutObjectOutput, error) {\r\n\targs := m.Called(ctx, params, optFns)\r\n\treturn args.Get(0).(*s3.PutObjectOutput), args.Error(1)\r\n}\r\n\r\nfunc (m *MockS3Client) ListObjectsV2(ctx context.Context, params *s3.ListObjectsV2Input, optFns ...func(*s3.Options)) (*s3.ListObjectsV2Output, error) {\r\n\targs := m.Called(ctx, params, optFns)\r\n\treturn args.Get(0).(*s3.ListObjectsV2Output), args.Error(1)\r\n}\r\n\r\nfunc (m *MockS3Client) DeleteObject(ctx context.Context, params *s3.DeleteObjectInput, optFns ...func(*s3.Options)) (*s3.DeleteObjectOutput, error) {\r\n\targs := m.Called(ctx, params, optFns)\r\n\treturn args.Get(0).(*s3.DeleteObjectOutput), args.Error(1)\r\n}\r\n\r\nfunc (m *MockS3Client) HeadObject(ctx context.Context, params *s3.HeadObjectInput, optFns ...func(*s3.Options)) (*s3.HeadObjectOutput, error) {\r\n\targs := m.Called(ctx, params, optFns)\r\n\treturn args.Get(0).(*s3.HeadObjectOutput), args.Error(1)\r\n}\r\n\r\nfunc TestS3StorageRead(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\texpectedContent := []byte(\"test content\")\r\n\tmockClient.On(\"GetObject\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.GetObjectOutput{\r\n\t\t\tBody: ioutil.NopCloser(bytes.NewReader(expectedContent)),\r\n\t\t},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\tcontent, err := s3Storage.Read(\"test.txt\")\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.Equal(t, expectedContent, content)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageWrite(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tcontent := []byte(\"test content\")\r\n\tmockClient.On(\"PutObject\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.PutObjectOutput{},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\terr := s3Storage.Write(\"test.txt\", content)\r\n\r\n\tassert.NoError(t, err)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageList(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tmockClient.On(\"ListObjectsV2\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.ListObjectsV2Output{\r\n\t\t\tContents: []types.Object{\r\n\t\t\t\t{Key: aws.String(\"file1.txt\")},\r\n\t\t\t\t{Key: aws.String(\"file2.txt\")},\r\n\t\t\t},\r\n\t\t},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\tfiles, err := s3Storage.List(\"prefix\")\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.Equal(t, []string{\"file1.txt\", \"file2.txt\"}, files)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageDelete(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tmockClient.On(\"DeleteObject\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.DeleteObjectOutput{},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\terr := s3Storage.Delete(\"test.txt\")\r\n\r\n\tassert.NoError(t, err)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageExists(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tmockClient.On(\"HeadObject\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.HeadObjectOutput{},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\texists, err := s3Storage.Exists(\"test.txt\")\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.True(t, exists)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageIsDirectory(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tmockClient.On(\"ListObjectsV2\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.ListObjectsV2Output{\r\n\t\t\tCommonPrefixes: []types.CommonPrefix{\r\n\t\t\t\t{Prefix: aws.String(\"test/\")},\r\n\t\t\t},\r\n\t\t},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\tisDir, err := s3Storage.IsDirectory(\"test/\")\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.True(t, isDir)\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n\r\nfunc TestS3StorageStat(t *testing.T) {\r\n\tmockClient := new(MockS3Client)\r\n\tmockLogger := new(MockLogger)\r\n\ts3Storage := \u0026S3Storage{\r\n\t\tclient: mockClient,\r\n\t\tbucket: \"test-bucket\",\r\n\t\tlogger: mockLogger,\r\n\t}\r\n\r\n\tlastModified := time.Now()\r\n\tmockClient.On(\"HeadObject\", mock.Anything, mock.Anything, mock.Anything).Return(\r\n\t\t\u0026s3.HeadObjectOutput{\r\n\t\t\tContentLength: aws.Int64(100),\r\n\t\t\tLastModified:  \u0026lastModified,\r\n\t\t},\r\n\t\tnil,\r\n\t)\r\n\r\n\tmockLogger.On(\"Debug\", mock.Anything, mock.Anything).Return()\r\n\r\n\tinfo, err := s3Storage.Stat(\"test.txt\")\r\n\r\n\tassert.NoError(t, err)\r\n\tassert.Equal(t, \"test.txt\", info.Name())\r\n\tassert.Equal(t, int64(100), info.Size())\r\n\tassert.Equal(t, lastModified, info.ModTime())\r\n\tmockClient.AssertExpectations(t)\r\n\tmockLogger.AssertExpectations(t)\r\n}\r\n",
    "size": 6743,
    "modTime": "2024-11-04T14:44:37.9738004+01:00",
    "path": "s3_test.go"
  },
  {
    "name": "storage.go",
    "content": "// internal/storage/storage.go\r\n\r\npackage storage\r\n\r\nimport (\r\n\t\"github.com/chrlesur/Ontology/internal/logger\"\r\n\t\"os\"\r\n\t\"io\"\r\n\t\"time\"\r\n)\r\n\r\n\r\n// FileInfo définit l'interface pour les informations sur les fichiers\r\ntype FileInfo interface {\r\n\tName() string       // Nom du fichier\r\n\tSize() int64        // Taille du fichier en octets\r\n\tMode() os.FileMode  // Mode du fichier (permissions, etc.)\r\n\tModTime() time.Time // Heure de la dernière modification\r\n\tIsDir() bool        // Indique si c'est un répertoire\r\n\tSys() interface{}   // Informations système sous-jacentes\r\n}\r\n\r\ntype Logger interface {\r\n    Debug(format string, args ...interface{})\r\n    Info(format string, args ...interface{})\r\n    Warning(format string, args ...interface{})\r\n    Error(format string, args ...interface{})\r\n}\r\n\r\n// Storage définit l'interface pour les opérations de stockage\r\ntype Storage interface {\r\n\t// Read lit le contenu d'un fichier\r\n\tRead(path string) ([]byte, error)\r\n\r\n\t// Write écrit des données dans un fichier\r\n\tWrite(path string, data []byte) error\r\n\r\n\t// List retourne une liste de chemins de fichiers dans le répertoire spécifié\r\n\tList(prefix string) ([]string, error)\r\n\r\n\t// Delete supprime un fichier\r\n\tDelete(path string) error\r\n\r\n\t// Exists vérifie si un fichier existe\r\n\tExists(path string) (bool, error)\r\n\r\n\t// IsDirectory vérifie si le chemin est un répertoire\r\n\tIsDirectory(path string) (bool, error)\r\n\r\n\t// Stat retourne les informations sur un fichier\r\n    Stat(path string) (FileInfo, error)\r\n\r\n\t// GetReader retourne un io.ReadCloser pour lire le contenu du fichier spécifié par le chemin.\r\n    // Il est de la responsabilité de l'appelant de fermer le reader une fois terminé.\r\n\tGetReader(path string) (io.ReadCloser, error)\r\n\r\n}\r\n\r\n// Constantes pour les types de stockage\r\nconst (\r\n\tLocalStorageType = \"local\"\r\n\tS3StorageType    = \"s3\"\r\n)\r\n\r\nvar log = logger.GetLogger()\r\n\r\n\r\n// LogStorageOperation est une fonction utilitaire pour logger les opérations de stockage\r\nfunc LogStorageOperation(operation, path string) {\r\n\tlog.Debug(\"Storage operation: %s, Path: %s\", operation, path)\r\n}\r\n\r\n// CheckError est une fonction utilitaire pour vérifier et logger les erreurs\r\nfunc CheckError(err error, operation, path string) {\r\n    if err != nil {\r\n        log.Error(\"Storage error: Operation: %s, Path: %s, Error: %v\", operation, path, err)\r\n    }\r\n}\r\n",
    "size": 2378,
    "modTime": "2024-11-05T09:23:06.5161489+01:00",
    "path": "storage.go"
  }
]